---
title: 'R-Script for Pre-Registration Experiment 1a: Direct evalautive ratings'
author: "Kathrin Reichmann"
date: "26 5 2021"
output:
  html_document: default
  pdf_document: default
input: direct.csv
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## General Information

The second task participants will do in the experiment is a direct evaluative rating task of CSs, GSs (stimuli from the same categories) -> "type_specific" . CSs stem from one of four different categories. Categories were either paired with positive USs, or with negative USs. CSs consisted of chinese characters with two components: one component defined the category-membership (predictive component), the other varied between exemplars (non-predictive component).

Direct Evaluative Ratings are conducted on a -100 to 100 scale. Difference scores are calculated by subtracting e.g. category1 [US+] - category2 [US-] for every participant and stimulus type.

Category size ("condition") is varied between-subjects (**one**: one exemplar per category vs. **many**: five exemplars per category).

Stimulus type ("type_discrete") is a within-subjects variable: consists of (**CS vs. GS**) for generalization and (**predictive vs. non-predictive**) for components

Here: 
  + Total number of participants: N = 200, 
  + nr. obs "CS" = 2 per participant, total: 400
  + nr.obs."GS" = 6, total: 1200 *-> because participants rated 3 GSs for every category. Reduce this to 1 GS?*
  + nr. observations "predictive component" = 2, total: 400

```{r prep, echo = FALSE, include = FALSE}
#set directory
knitr::opts_knit$set(root.dir = "C:/Users/reich/Documents/GitHub/CSCond_analysis/Study1_EC/data")

#load  packages
library(dplyr)
library(tidyverse)
library(ggplot2)
library(lme4)
library(modelsummary)

#functions
CI <- function(x) qnorm(0.975)*sd(x)/sqrt(length(x))
se <- function(x) sd(x)/sqrt(length(x))

```

```{r prepare data for generalization analysis, echo = FALSE, include = FALSE}

#read table
direct <- read.csv2('direct.csv', header = TRUE)
str(direct)

#convert to factor
as_factor <- c("subject", "val", "condition_code", "condition", "measure", "measure_code", "type", "type_specific", "category", "cs_selected")

for (factor in as_factor){
  direct[, factor] <- as.factor(direct[,factor])
}

direct$type_specific <- factor(direct$type_specific, levels = c("CS", "GS same", "GS different", "Feature", "Group"))

#!! change in new study?
## randomly select 1 CSs for many_one:
new_one <- direct[direct$condition == "one_one",]
new_many <- direct[direct$condition == "many_one",]
new_many <- new_many[!new_many$type_specific == "CS",]
new_direct <- rbind(new_one, new_many)

for (subject in unique(direct$subject)){
  if (direct$condition[direct$subject == subject] == "many_one"){
    for (cat in 1:4){
      temp <- direct[direct$subject == subject & direct$type_specific == "CS" & direct$category == cat,]
      select <- temp[1,]
      new_direct <- rbind(new_direct, select)
    }
  }
}

new_direct$type <- NULL

## rename many_one to many and one_one to one
new_direct$condition <- factor(new_direct$condition, labels = c("many", "one"), levels = c("many_one", "one_one"))

```

## (1) Testing H1: Generalization

### Hypothesis 1: 
Generalization towards novel stimuli is wider in the "many" condition than in the "one" condition.

Continous Predictor: CS Ratings (-100 to 100)
Categorical Predictor (between-subjects variable): condition; effect coded (-0.5 one, 0.5 many)
Categorical Predictor (within-subjects variable): valence, effect coded (-0.5 one, 0.5 many)
Continous Outcome: GS Ratings (-100 to 100)

Subjects N = 200, nr. of total observations: 1600 (400 for CSs, 1200 for GSs)

(H1)
*significant interaction condition x CS*

-> the relationship of CSs and GSs is qualified by condition
-> slope is steeper in "many" condition than in "one" condition (slope parameter estimate is more positive for many than one)


### Plot raw data: 

```{r prep data for generalization analysis, include = FALSE, echo = FALSE}

#(1) mean scores for every category and participant
#with category:
#centerDirect <- aggregate(response ~ subject + condition + type_specific + val + category, new_direct, mean)

#without category:
centerDirect <- aggregate(response ~ subject + condition + type_specific + val, new_direct, mean)

#look only at "CS" and "GS"
centerDirect <- centerDirect[!centerDirect$type_specific =="GS different", ]
centerDirect <- centerDirect[!centerDirect$type_specific == "Group",]
centerDirect <- centerDirect[!centerDirect$type_specific == "Feature",]


## rename many_one to many and one_one to one
centerDirect$condition <- factor(centerDirect$condition, labels = c("many", "one"), levels = c("many_one", "one_one"))

##categorical variable: generalization as discrete
centerDirect$type_discrete <- factor(centerDirect$type_specific, labels = c("CS", "GS"), levels = c("CS", "GS same"))

#reverse dummy coding for condiiton
centerDirect$condition <- factor(centerDirect$condition, labels = c("one", "many"), levels = c("one", "many"))

#(2) use CS as predictor for GS

multiLevel <- centerDirect[centerDirect$type_discrete == "CS",]
respGS <- centerDirect[centerDirect$type_discrete == "GS",]
multiLevel$GS <- respGS$response
multiLevel$CS <- multiLevel$response
multiLevel$response <- NULL
multiLevel$type_specific <- NULL
multiLevel$type_discrete <- NULL
head(multiLevel)
#z-standardize GS and CS
#multiLevel$GS <- scale (multiLevel$GS, center = TRUE, scale = TRUE)
#multiLevel$CS <- scale (multiLevel$CS, center = TRUE, scale = TRUE)


```

```{r plot raw data, include = TRUE, echo = FALSE}

#plot some individual slopes for condition "one"

'
indPlotData <- HLM[1:200,]
indPlotData <- indPlotData[order(indPlotData$subject),]

#plot some individual slopes for condition "many"
indPlot3 <- ggplot(indPlotData[!indPlotData$condition == "one",], aes(x = type_discrete, y = diff, group = subject, color = condition, shape = condition)) +
  facet_wrap(.~ subject, nrow = 5) +
  geom_point(show.legend = TRUE, alpha = .6) +
  geom_smooth(method = "lm", alpha = .6, se = FALSE) +  
  scale_color_brewer(palette = "Paired") 
indPlot3

#plot some individual slopes for condition "one"
indPlotData <- HLM[1:280,]
indPlotData <- indPlotData[order(indPlotData$subject),]
indPlot3 <- ggplot(indPlotData[!indPlotData$condition == "many",], aes(x = type_discrete, y = diff, group = subject, color = condition, shape = condition)) +
  facet_wrap(.~ subject, nrow = 5) +
  geom_point(show.legend = TRUE, alpha = .6) +
  geom_smooth(method = "lm", alpha = .6, se = FALSE) +  
  scale_color_brewer(palette = "Paired") 
indPlot3
'

#condition_code: 0 =  many

dotplot <- ggplot(multiLevel, aes (x = CS, y = GS, color = condition)) +
  facet_grid(. ~ condition) +
  geom_point(show.legend = TRUE) +
  ggtitle("Direct Evaluative Ratings\n") + 
  geom_smooth(method = 'lm', aes (color = condition)) +
  scale_color_brewer(palette = "Set2") +
  scale_x_continuous(name = "\nCS Ratings") +
  scale_y_continuous (name = "GS Ratings\n") + 
  theme_classic() +
  labs(color = "Condition") +
  theme(plot.title = element_text (hjust = 0.5, face = "bold", size = 14),
        text = element_text(size=14))
dotplot


```

### multiple regression without random slopes: model 1 (CS only) ("Impulsvortrag")

```{r model1, echo = FALSE, include = TRUE}

#effect coding of condition
multiLevel$condition_effect <- 0
for (line in 1:dim(HLM)[1]){
  if (multiLevel$condition[line] == "one"){
    multiLevel$condition_effect[line] <- -0.5
  } else {
    multiLevel$condition_effect[line] <- 0.5
  }
}
multiLevel$condition_effect
str(multiLevel)

model1 <- lm(GS ~ CS, data = multiLevel)
summary(model1)

```


### multiple regression without random slopes: model 2 (+ condition) ("Impulsvortrag")

```{r model 2, echo = FALSE, include = TRUE}

model2 <- lm(GS ~ CS*condition_effect, data = multiLevel)
summary(model2)
anova(model2)

model.matrix(GS ~ CS*condition_effect, data = multiLevel)
plot(model2)


#Effektkodierung -1 und 1
'
options(contrasts = c("contr.sum", "contr.poly"))

model2 <- lm(GS ~ CS*condition, data = multiLevel)
summary(model2)
anova(model2)

model.matrix(GS ~ CS*condition, data = multiLevel)
plot(model2)
'

```

###parameter interpretation:

Dummy Coded: Stimulus Type (0 - CS, 1 - GS) and Condition (0 - One, 1 - Many)


Interpretation: 

+ **intercept estimate:** mean difference score for „CS“ is 64.91 in the „one“ condition.

+ **ConditionMany [Gruppeneffekt]:**  On average, the difference score is reduced by -0.75 points for CSs in the „many“ condition in comparison to CSs in the „one“ condition. **confirmation of H1a: predicts non-significant result**

+ **Type_discreteGS [Generalisierung]:** In the „one“ condition, the mean difference score is reduced by -40.30 points for GSs, in comparison to CSs. -> not interesting

+ **Type_discreteGS:conditionMany:** In "many" condition, the average difference score for GSs is 22.91 higher than the average difference scores for GSs in the "one" condition -> higher diff scores indicate wider generalization **confirmation of H2b: predicts significant result -> use for power analysis?**

+ **Random intercept [45.72]:** variation of intercept across subjects: variation goes beyond the fixed effect of stimulus type [-40.4]

+ **Random slopes [8.22]:** variation of slopes across subjects: individual differences in the degree of generalization (here: in their "GS" ratings) -> individuals differ beyond the individual differences explained by the „condition“ variable



### multiple regression without random slopes: simple slope for condition: Many

```{r simple slope 1, echo = FALSE, include = TRUE}

#simple slope for condition: Many
options(contrasts = c("contr.SAS","contr.poly")) #Dummykodierung

model2 <- lm(GS ~ CS*condition, data = multiLevel)
summary(model2)
anova(model2)

model.matrix(GS ~ CS*condition, data = multiLevel)
plot(model2)

```



### multiple regression without random slopes: simple slope for condition: One

```{r simple slope 2, echo = FALSE, include = TRUE}


#simple slope for Many
options(contrasts = c("contr.treatment","contr.poly")) #Dummykodierung

model2 <- lm(GS ~ CS*condition, data = multiLevel)
summary(model2)
anova(model2)

model.matrix(GS ~ CS*condition, data = multiLevel)
plot(model2)

```


### multiple regression without random slopes: model 3 (+ valence) ("Impulsvortrag")


```{r model 3,  echo = FALSE, include = TRUE}

#### keep this model in mind for later
model3 <- lm(GS ~ CS*condition*val, data = multiLevel)
summary(model3)


#condition_code: 0 =  many

dotplot <- ggplot(multiLevel, aes (x = CS, y = GS, color = val)) +
  facet_grid(. ~ condition) +
  geom_point(show.legend = TRUE) +
  ggtitle("Direct Evaluative Ratings\n") + 
  geom_smooth(method = 'lm', aes (color = condition)) +
  scale_color_brewer(palette = "Set2") +
  scale_x_continuous(name = "\nCS Ratings") +
  scale_y_continuous (name = "GS Ratings\n") + 
  theme_classic() +
  labs(color = "Condition") +
  theme(plot.title = element_text (hjust = 0.5, face = "bold", size = 14),
        text = element_text(size=14))
dotplot


```

### model comparison:

```{r model comparison,  echo = TRUE, include = TRUE}
anova(model1, model2, model3)
```



## (2) Testing H2: CS Components

### Hypothesis 2: 
Evaluative ratings differ between predictive and non-predictive components for "many" condition. 
No difference between the components in the "one" condition.

Explanation: In the „many“ condition, the EC effect gets attached to the category-defining feature, while in the „one“ condition, the EC effect gets attached to the whole stimulus


Dummy Coded: Stimulus Component (0 - Non-Predictive , 1 - Predictive) and Condition (0 - One, 1 - Many)

(2a)
*non-significant fixed effect of stimulus component, when ref. category is "one"*

-> no difference between components in **"one" condition**
  
(2b)
*significant fixed effect for the cross-level interaction stimulus component x condition, and fixed effect of condition, when ref. category is "one". *

-> difference between components in **many condition** goes beyond difference in components in "one" condition *-> confirms the hypothesis only indirectly...*

-> simple slope: significant difference between components in the **many condition** : significant decrease in difference scores for the "predictive" component in comparison to the "non-predictive" component


### Plot raw data [predictive, non-predictive is hypothetical]: 

```{r prep data for component analysis, echo = FALSE, include = FALSE}

#right now: do not take different targets into account (participants are nested within targets)
temp <- aggregate(response ~ subject + condition + val + type_specific + category, new_direct, mean)
temp$nr_obs <- aggregate(response ~ subject + condition + val + type_specific + category, new_direct, length)[[6]]
temp$nr_obs

## order data
temp <- temp[order(temp$subject, temp$val, temp$type_specific),]

## cbind positive and negative scores
HLMpos <- temp[temp$val == "pos",]
HLMpos$pos <- HLMpos$response
HLMpos$response <- NULL

HLMneg <- temp[temp$val == "neg",]
HLMneg$neg <- HLMneg$response
HLM <- cbind(HLMpos, HLMneg$neg, HLMneg$category)

HLM$val <- NULL
HLM$neg <- HLM$`HLMneg$neg`
HLM$`HLMneg$neg` <- NULL

## calculate difference scores
HLM$diff <- HLM$pos - HLM$neg

#reverse dummy coding for condiiton
HLM$condition <- factor(HLM$condition, labels = c("one", "many"), levels = c("one", "many"))

## discard levels of type we don't need
HLM <- HLM[!HLM$type_specific == "Group",]
HLM <- HLM[!HLM$type_specific == "GS different",]
HLM <- HLM[!HLM$type_specific == "GS same",]
HLM <- HLM[!HLM$type_specific == "CS",]


##categorical variable: generalization as discrete
HLM$type_discrete <- factor(HLM$type_specific, labels = c("predictive"), levels = c("Feature"))


```

```{r plot data with hypothetical results, include = TRUE, echo = FALSE}

means <- aggregate(diff ~ type_discrete + condition, HLM, mean)
means$se <- aggregate(diff ~ type_discrete + condition, HLM, se)[[3]]
means

##add hypothetical data
means$type_discrete <- as.character(means$type_discrete)
hypoMany <- c("non-predictive", "many", 18, 0)
hypoOne <- c("non-predictive", "one", 22, 0)
means <- rbind(means, hypoMany, hypoOne)
means$type_discrete <- as.factor(means$type_discrete)
means$diff <- as.numeric(means$diff)
means$se <- as.numeric(means$se)
means

#barplot with standard errors
barplotDiff <- ggplot(means, aes (x = condition, y = diff, fill = type_discrete)) +
  geom_bar(stat = 'identity', position = position_dodge(), show.legend = TRUE) +
  geom_errorbar(aes(ymin= diff - se, ymax= diff + se), width=.2,
                position=position_dodge(.9)) +
  ggtitle("Evaluative Ratings for Components (non-predictive is hypothetical)") + 
  scale_fill_brewer(palette = "Set3") +
  scale_x_discrete(name = "\nCondition") +
  scale_y_continuous (name = "Mean Difference Scores\n", breaks = seq(0, 100, 10), limits = c(0, 100)) + 
  theme_classic() +
  labs(fill = "Component") +
  theme(plot.title = element_text (hjust = 0.5, face = "bold", size = 12))
barplotDiff

```

### model for data analysis:

```{r multilevel model, echo = TRUE, include = TRUE}

#hypothetical second level of factor type_discrete
HLM2 <- HLM
HLM2$type_discrete <- factor(HLM$type_specific, labels = c("non-predictive"), levels = c("Feature"))
HLM <- rbind(HLM2, HLM)

#reverse dummy coding for condition
HLM$condition <- factor(HLM$condition, labels = c("one", "many"), levels = c("one", "many"))


##### random intercept model with fixed effect of stimulus type
model1 <- lmer(diff ~ type_discrete + (1|subject), data = HLM, REML = FALSE)
summary(model1)

##### + random slope
model2 <- lmer(diff ~ type_discrete + (type_discrete|subject), data = HLM, REML = FALSE)
summary(model2)

##### + between-subjects factor condition
model3 <- lmer(diff ~ type_discrete*condition + (type_discrete|subject), data = HLM, REML = FALSE)

#### here: results are made up and thus make no sense
summary(model3)

```

Dummy Coded: Stimulus Component (0 - Non-Predictive , 1 - Predictive) and Condition (0 - One, 1 - Many)

Interpretation: (what we would predict)

+ **intercept estimate:** mean difference score for „non-predictive“ is XX in the „one“ condition.

+ **ConditionMany [Gruppeneffekt]:**  On average, the difference score is reduced by XX points for non-predictive in the „many“ condition in comparison to non-predictive in the „one“ condition. -> **hypothesis 2b: should be significant & negative**

+ **Type_discretePredictive [Component]:** In the „one“ condition, the mean difference score increases by XX points for predictive components, in comparison to non-predictive components -> **hypothesis 2a: should not be significant**

+ **Type_discretePredictive:conditionMany:** In the "many" condition, the average difference score for "predictive" components is XX higher than the average difference score for "predictive" Components in the "one" condition -> **hypothesis 2b: should be significant & positive**

+ **Random intercept [XX]:** variation of intercept across subjects: variation goes beyond the fixed effect of stimulus type [XX]

+ **Random slopes [XX]:** variation of slopes across subjects: individual differences in the evaluations of the components -> individuals differ beyond the individual differences explained by the „condition“ variable

```{r observe H1a and H2b directly, include = TRUE, echo = FALSE}

one <- lm (diff ~ type_discrete, data = HLM[HLM$condition == "one", ])
summary(one)

many <- lm (diff ~ type_discrete, data = HLM[HLM$condition == "many", ])
summary(many)

```

Interpretation: (what we would predict)

**H2a**: ("one" is non-significant) in line with the prediction that components are evaluated equally in the "one" condition

**H2b**: ("many" is significant, positive parameter) in line with the prediction that predictive components have higher difference scores than non-predictive components 

## (3) Alternative way of approaching H1 (use "CS ratings" as a predictor, control for categories)

### Hypothesis 1: 
Generalization towards novel stimuli is wider in the "many" condition than in the "one" condition.

CS ratings as the continuous predictor. GS as the outcome variable. Both z-standardized.
Condition as the between-subjects variable.

H1a:
*significant interaction CS and condition*
-> predictive value of CS to predict GS ratings depends on the different conditions
-> slope is steeper for "many" than for "one"

### plot prediction of "GS" with "CS", controlling for categories

```{r plot new model, include = TRUE, echo = FALSE}


#(1) mean scores for every category and participant
centerDirect <- aggregate(response ~ subject + condition + category + type_specific + val, new_direct, mean)
#condition_code: 0 =  many


#(2) use CS as predictor for GS same
multiLevel <- centerDirect[centerDirect$type_specific == "CS",]
respGS <- centerDirect[centerDirect$type_specific == "GS same",]
multiLevel$GS <- respGS$response
multiLevel$CS <- multiLevel$response
multiLevel$response <- NULL
multiLevel$type_specific <- NULL

#z-standardize GS and CS
multiLevel$GS <- scale (multiLevel$GS, center = TRUE, scale = TRUE)
multiLevel$CS <- scale (multiLevel$CS, center = TRUE, scale = TRUE)

#(3) plot the two different levels involved in the analysis

dotplot <- ggplot(multiLevel, aes (x = CS, y = GS, color = category)) +
  facet_grid(. ~ condition) +
  geom_point(show.legend = TRUE) +
  geom_smooth(method = 'lm') +
  scale_color_brewer(palette = "Paired") +
  scale_x_continuous(name = "\nCS Ratings") +
  scale_y_continuous (name = "GS (new) Ratings\n") + 
  theme_classic() +
  labs(fill = "Categories") +
  theme(plot.title = element_text (hjust = 0.5, face = "bold", size = 12))
dotplot

```

```{r models, include = FALSE, echo = FALSE}


#(4) build up the models
#-> work on this a bit more

#add random intercept for category
lmer1 <- lmer(GS ~ 1 + (1| category), data = multiLevel, REML = FALSE)

#add CSs as predictor
lmer2 <- lmer(GS ~ CS + (1 | category), data = multiLevel, REML = FALSE)

#add random slopes
lmer3 <- lmer(GS ~ CS + (CS | category), data = multiLevel, REML = FALSE )

#add interaction with condition
lmer4 <- lmer(GS ~ CS*condition + (CS| category), data = multiLevel, REML = FALSE )

#(5) pick best model
anova(lmer1, lmer2, lmer3, lmer4)

#(6) results
summary(lmer4)

```

