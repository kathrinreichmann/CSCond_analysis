indirect$type_specific <- factor(indirect$type_specific, levels = c("CS", "GS same", "GS different", "Feature", "Group"))
## randomly select 1 CS for many_one:
new_one <- indirect[indirect$condition == "one_one",]
new_many <- indirect[indirect$condition == "many_one",]
#remove the original CS evaluations
new_many <- new_many[!new_many$type_specific == "CS",]
new_indirect <- rbind(new_one, new_many)
for (subject in unique(indirect$subject)){
if (indirect$condition[indirect$subject == subject] == "many_one"){
for (cat in 1:4){
temp <- indirect[indirect$subject == subject & indirect$type_specific == "CS" & indirect$category == cat,]
select <- temp[1,]
#concat only 1 CS rating per participant
new_indirect <- rbind(new_indirect, select)
}
}
}
head(new_indirect)
temp <- new_indirect
# order data
temp <- temp[order(temp$subject, temp$val, temp$type_specific),]
# omit information we don't need
temp <- temp[!temp$type_specific =="GS different", ]
temp <- temp[!temp$type_specific == "Feature",]
## rename many_one to many and one_one to one
temp$condition <- factor(temp$condition, labels = c("one", "many"), levels = c("one_one", "many_one"))
##categorical variable: generalization as discrete
temp$type_specific <- factor(temp$type_specific, labels = c("CS", "GS"), levels = c("CS", "GS same"))
head(temp)
## effect code variables
#condition
temp$condition_effect <- 0
for (line in 1:dim(temp)[1]){
if (temp$condition[line] == "one"){
temp$condition_effect[line] <- -0.5
} else {
temp$condition_effect[line] <- 0.5
}
}
temp$condition_effect
#valence
temp$val_effect <- 0
for (line in 1:dim(temp)[1]){
if (temp$val[line] == "neg"){
temp$val_effect[line] <- -0.5
} else {
temp$val_effect[line] <- 0.5
}
}
temp$condition_effect
str(temp)
#type
temp$type_effect <- 0
for (line in 1:dim(temp)[1]){
if (temp$type_specific[line] == "CS"){
temp$type_effect[line] <- -0.5
} else {
temp$type_effect[line] <- 0.5
}
}
temp$type_specific
str(temp)
#set default to dummy coding
options(contrasts = c("contr.treatment", "contr.poly"))
### specify models
indirect <- temp
indirect$response <- as.numeric(indirect$response)
indirect <- indirect[order(indirect$subject, indirect$val, indirect$type_specific, indirect$category),]
indirectProp <- aggregate(response ~ subject + val_effect + val + type_effect + type_specific
+ condition + condition_effect, indirect, sum)
indirectProp$length <- aggregate(response ~ subject + val_effect + val + type_effect + type_specific + condition + condition_effect, indirect, length)[[8]]
indirectProp$prop <- indirectProp$response/indirectProp$length
```
### AMP
condition (-0.5 = one, 0.5 = many), type (-0.5 = CS, 0.5 = GS), val (-0.5 = neg, 0.5 = pos)
Model with random intercepts for participants:
glmer(response ~ condition (effect coded) * type (effect coded) * val (effect coded) + (1|subject))
```{r, echo = TRUE, include = TRUE}
#analysis 2: with valence as a factor
#random intercepts
glmer1 <- glmer(response ~ val_effect*condition_effect*type_effect
+ (1|subject),
indirect, binomial)
#random slopes
glmer2 <- glmer(response ~ val_effect*condition_effect*type_effect
+ (val_effect + type_effect|subject),
indirect, binomial)
anova(glmer1, glmer2)
test <- lmer(prop ~ val_effect*condition_effect*type_effect
+ (val_effect + type_effect|subject),
indirectProp, REML=FALSE)
#choose model2
```
The difference in deviance between Model 1 and Model 2 is significant XÂ²(9, 3191) = 36.79, p < .001 This indicates that including random slope effects for valence and stimulus type contributes to a better fitting model than a mere random intercept effect.
```{r,  echo = FALSE, include = TRUE}
summary(glmer2, corr = FALSE)
```
Parameter Interpretation: glmer2
**Random Intercept subjects = 10.81** -> variation of intercepts across subjects (goes beyond the fixed effect of stimulus type -> there are substantial interindividual differences in the average evaluative ratings of participants)
**Random Slopes Val = 39.86** -> variation of intercepts across subjects (goes beyond the fixed effect of stimulus type -> there are substantial interindividual differences in the average evaluative ratings of participants)
**Random Slopes Type = 39.86** -> variation of intercepts across subjects (goes beyond the fixed effect of stimulus type -> there are substantial interindividual differences in the average evaluative ratings of participants)
**Intercept = 3.64** -> Grand mean (average ratings were 3.64)
**Fixed Effect Condition = -7.31** -> main effect condition: On average, ratings in the "many" condition were 7.31 points lower in the "many" condition than in the "one" condition.
**Fixed Effect Type = -3.11** -> main effect type: the estimated mean difference between stimulus types in ratings was 3.11: 3.11 points lower in for "GSs" than for "CSs". n.s.
**Fixed Effect Valence = 50.11** -> main effect valence: the estimated mean difference between positive and negative valence in ratings was 50.11: 50.11 points higher for "positive" than for "negative".
**Interaction Type x Condition = 2.01** -> interaction effect condition*type: the difference between CSs and GSs was not significantly qualified by condition, but was 2.01 points higher on average in the "one" condition than in the "many" condition.
**Interaction Val x Condition = 10.71** -> the difference between pos and neg valence was not significantly qualified by the condition, but was 10.71 points higher on average in the "many" condition than in the "one" condition.
**Interaction Val x Type = -28.85** -> the difference between pos and neg valence was qualified by the type of stimuli, being on average 28.85 points higher for a CSs than GSs.
<span style = "color:darkblue;">
**Interaction Type x Condition x Val = 22.91** -> significant three-way interaction condition x type x val: the interaction of US valence (EC effect) and stimulus type was qualified by the condition, being 22.91 points higher in the "one" condition than in the "many" condition.
*-> H1*
</span>
```{r, echo = TRUE, include = FALSE}
#check if interpretations make sense
lmer1_analysis <- aggregate(response ~ val*type_specific*condition, direct, mean)
aggregate(response ~ type_specific, lmer1_analysis, mean)
aggregate(response ~ val, lmer1_analysis, mean)
aggregate(response ~ condition, lmer1_analysis, mean)
aggregate(response ~ type_specific*condition, lmer1_analysis, mean) #one(9.35 - 5.23) - many(1 + 1)
aggregate(response ~ val*condition, lmer1_analysis, mean) #many(27.7 + 27.7) - one(15.08+29.67)
aggregate(response ~ val*type_specific, lmer1_analysis, mean) #CS(27.7 + 37.46) - GS(15.76+19.93)
lmer1_analysis #three-way interaction: (one: (23+41) - (7 + 17)) - (many: (31 + 33.12) - (24.46 + 22.31))
```
#### simple slopes to test the significance of the EC effect (diff between neg and pos valence) for each condition and stimulus type:
lmer(ratings ~ category size * stimulus type
+ US valence(effect coded):category size(dummy coded):stimulus type(dummy coded)
+ (stimulus type * US valence | subject))
```{r, echo = TRUE, include = TRUE}
#model2
glmer2_2 <- glmer(response ~ condition_effect*type_effect + val_effect:condition:type_specific
+ (val_effect+type_effect|subject),
indirect, binomial)
summary(glmer2_2, corr = FALSE)
```
Parameter Interpretation: glmer2_1
The EC effect was significant in both conditions for both CSs and GSs.
#### simple slopes to test if the EC effect (diff between neg and pos valence) differs significantly between the two category size conditions, for each stimulus type separately.
glmer(ratings ~ stimulus type * US valence + stimulus type * category size
+ US valence(effect coded) : category size(effect coded) : stimulus type(dummy coded)
+ (stimulus type * US valence | subject))
```{r, echo = TRUE, include = TRUE}
#model3
glmer2_3 <- glmer(response ~ type_effect*val_effect + type_effect*condition_effect +
+ condition_effect:val_effect:type_specific
+ (val_effect+type_effect|subject),
indirect, binomial)
summary(glmer2_3, corr = FALSE)
```
**Interaction Condition x val x typeCS = -11.14** -> the difference of neg and pos valence is not significantly qualified by condition for CSs, but was 11.15 points higher in the "one" condition than in the "many" condition
**Interaction Condition x val x typeGS = 16.27** -> the difference of neg and pos valence is significantly qualified by condition for GSs, and was on average 16.27 points higher in the "many" condition than in the "one" condition.
<span style = "color:red;"> This confirms H1. </span>
#### Plot:
```{r, echo = TRUE, include = FALSE}
#toublecheck
lmer1_analysis
#CSs: (23.1+41.8)-(31+33)many
aggregate(response ~ val*condition, direct[direct$type_specific == "CS",], mean)
#one:
aggregate(response ~ val*condition, direct[direct$type_specific == "GS",], mean)
#one:(7+17.5) - (24.46+22.31)
```
```{r, echo = FALSE, include = TRUE}
#plot indirect
indirect_plot1 <- aggregate(response ~ condition*type_specific*val, indirect, mean)
indirect_plot1$se <- aggregate(response ~ condition*type_specific*val, indirect, se) [[4]]
barplot2 <- ggplot(indirect_plot1, aes (y = response, x = condition, fill = val)) +
facet_grid(. ~ type_specific) +
geom_col(position = position_dodge()) +
geom_errorbar(aes(ymin= response - se, ymax= response + se), width=.2,
position=position_dodge(.9)) +
geom_hline(yintercept = 0.5) +
ggtitle("AMP\n") +
scale_fill_brewer(palette = "Paired") +
scale_x_discrete(name = "\n Condition") +
scale_y_continuous (name = "AMP responses\n", limits = c(0,1)) +
theme_classic() +
labs(fill = "Valence") +
theme(plot.title = element_text (hjust = 0.5, face = "bold", size = 14),
text = element_text(size=14))
barplot2
```
```{r, echo = FALSE, include = FALSE}
# recognition memory ------------------------------------------------------
setwd(DRM)
memory <- read.csv2("memory1.csv", header = TRUE)
str(memory)
#delete columns we don't need
memory$X <- NULL
memory$memoryCorrect <- NULL
memory$trial_index <- NULL
memory$task <- NULL
memory$rt <- NULL
#rename condition
names(memory)[names(memory) == "condition1"] <- "condition"
#delete trials with timeout
memory <- memory[!memory$timeout == "true",]
str(memory)
#as factor
as_factor <- c("subject", "condition", "type", "category", "cs_selected")
for (factor in as_factor){
memory[, factor] <- as.factor(memory[,factor])
}
temp <- memory
# omit information we don't need
temp <- temp[!temp$type =="CSpred", ]
temp <- temp[!temp$type =="CSnonpred", ]
temp <- temp[!temp$type =="GSnew", ]
temp <- temp[!temp$type == "distractor",]
temp <- temp[!temp$condition == "many_fill",]
# order data
temp <- temp[order(temp$subject, temp$type),]
## rename many_one to many and one_one to one
temp$condition <- factor(temp$condition, labels = c("one", "many"), levels = c("one_one", "many_one"))
##categorical variable: generalization as discrete
temp$type <- factor(temp$type, labels = c("CS", "GS"), levels = c("CS", "GSold"))
head(temp)
## effect code variables
#condition, one = 0.5
temp$condition_effect <- 0
for (line in 1:dim(temp)[1]){
if (temp$condition[line] == "one"){
temp$condition_effect[line] <- -0.5
} else {
temp$condition_effect[line] <- 0.5
}
}
temp$condition_effect
#type, GS = 0.5
temp$type_effect <- 0
for (line in 1:dim(temp)[1]){
if (temp$type[line] == "CS"){
temp$type_effect[line] <- -0.5
} else  {
temp$type_effect[line] <- 0.5
}
}
temp$type_effect
str(temp)
memory <- temp
memory$memoryResp <- as.numeric(memory$memoryResp)
memory <- memory[order(memory$subject, memory$type, memory$category),]
str(memory)
#for plotting
memoryProp <- aggregate(memoryResp ~ subject + type + condition, memory, sum)
memoryProp$length <- aggregate(memoryResp ~ subject + type + condition, memory, length)[[4]]
memoryProp$prop <- memoryProp$memoryResp/memoryProp$length
hist(memoryProp$prop)
head(memoryProp)
##### analysis 1: glmers
#set default to dummy coding
options(contrasts = c("contr.treatment", "contr.poly"))
```
**Analysis of DRM Results**
**H2**: Higher false memory rates when the category size is large, in comparison to the small category size. This translates into a significant category size x stimulus type interaction. We expect this for the recognition memory measure.
-> false memory rates:
for memory responses (1 = "old", 0 = "new")
condition (-0.5 = one, 0.5 = many), type (-0.5 = CS, 0.5 = GS)
Model with random intercepts for participants and stimulus:
glmer(memoryResp ~ condition* type + (1|subject) + (1|stimulus))
*signifikant interaction: H2*
```{r, echo = TRUE, include = TRUE}
#random intercept and slope for participants
glmer1 <- glmer(memoryResp ~ condition_effect * type_effect
+ (1|subject),
memory, binomial)
#random intercept and slope for stimuli for participants
glmer2 <- glmer(memoryResp ~ condition_effect*type_effect
+ (1|subject) + (1|cs_selected),
memory, binomial)
#random intercept and slope for stimuli for participants
glmer3 <- glmer(memoryResp ~ condition_effect*type_effect
+ (type_effect|subject) + (1|cs_selected),
memory, binomial)
#random intercept and slope for targets (does not converge)
glmer4 <- glmer(memoryResp ~ condition_effect*type_effect
+ (type_effect|subject) + (type_effect|cs_selected),
memory, binomial)
anova(glmer1, glmer2, glmer3, glmer4)
#model choice: glmer2
summary(glmer2, corr = FALSE)
```
simple slopes:
Model with random intercepts for participants and random intercepts for targets:
glmer(memoryResp ~ type (effect coded) + condition (effect coded)* type (dummy coded) +  (1|subject) + (1|target))
```{r, echo = TRUE, include = TRUE}
#analyze simple slopes (even though three-way-interaction is not significant)
glmer2_2 <- glmer(memoryResp ~ type_effect + type:condition_effect
+ (1|subject) + (1|cs_selected), memory, binomial)
summary(glmer2_2, corr = FALSE)
```
```{r, echo = FALSE, include = TRUE}
#plot model1
memory_plot2 <- aggregate(memoryResp ~ condition + type, memory, mean)
memory_plot2$se <- aggregate(memoryResp ~ condition + type, memory, se)[[3]]
barplot1 <- ggplot(memory_plot2, aes (y = memoryResp, x = type, fill = condition)) +
geom_col(position = position_dodge()) +
geom_errorbar(aes(ymin= memoryResp - se, ymax= memoryResp + se), width=.2,
position=position_dodge(.9)) +
ggtitle("DRM\n") +
scale_fill_brewer(palette = "Paired") +
scale_x_discrete(name = "\n Type") +
scale_y_continuous (name = '"old" response rates\n') +
theme_classic() +
labs(fill = "Condition") +
theme(plot.title = element_text (hjust = 0.5, face = "bold", size = 14),
text = element_text(size=14))
barplot1
```
knitr::opts_chunk$set(echo = TRUE)
#random intercepts
lmer1 <- lmer(response ~ val_effect*condition_effect*type_effect
+ (1|subject),
direct, REML = FALSE)
anova(lmer1, lmer2)
lmer1
summary(lmer2)
lmer2
#random slopes
lmer2 <- lmer(response ~ val_effect*condition_effect*type_effect
+ (val_effect+type_effect|subject),
direct, REML = FALSE)
lmer3 <- lmer(response ~ val_effect*condition_effect*type_effect
+ (val_effect*type_effect|subject),
direct, REML = FALSE)
anova(lmer1, lmer2, lmer3)
summary(lmer2, corr = FALSE)
plot(lmer2)
#random intercepts
glmer1 <- glmer(response ~ val_effect*condition_effect*type_effect
+ (1|subject),
indirect, binomial)
#random intercepts
glmer1 <- glmer(response ~ val_effect*condition_effect*type_effect
+ (1|subject),
indirect, binomial)
#random slopes
glmer2 <- glmer(response ~ val_effect*condition_effect*type_effect
+ (val_effect + type_effect|subject),
indirect, binomial)
anova(glmer1, glmer2)
summary(glmer2, corr = FALSE)
head(indirect)
exp(0.73919)
#check if interpretations make sense
glmer2_analysis <- aggregate(response ~ val*type_specific*condition, indirect, mean)
#check if interpretations make sense
glmer2_analysis <- aggregate(response ~ val*type_specific*condition, indirect, mean)
aggregate(response ~ type_specific, glmer2_analysis, mean)
aggregate(response ~ val, glmer2_analysis, mean)
0.47/0.64
exp(-1.66)
exp(0.24)
aggregate(response ~ condition, glmer2_analysis, mean)
log(0.58)/1-log(0.58)
log(0.58)/log(0.53)
exp(-0.21)
aggregate(response ~ val, glmer2_analysis, mean)
exp(-0.04)
aggregate(response ~ type_specific, glmer2_analysis, mean)
#model2
glmer2_2 <- glmer(response ~ condition_effect*type_effect + val_effect:condition:type_specific
+ (val_effect+type_effect|subject),
indirect, binomial)
summary(glmer2_2, corr = FALSE)
#model3
glmer2_3 <- glmer(response ~ type_effect*val_effect + type_effect*condition_effect +
+ condition_effect:val_effect:type_specific
+ (val_effect+type_effect|subject),
indirect, binomial)
summary(glmer2_3, corr = FALSE)
exp(0.14)
exp(0.44)
anova(glmer2, glmer2_2, glmer2_3)
glmer2_analysis
67.33-49
65.64-44
65.64-43
64.65-43
64.65-42.93
18.33/100
21.72/0.1833
61.95 - 42.42
62.38-52.5
19.53/(9.88/100)
exp(0.442)
21.75/(18.33/100)
21.75/(100-21.75)
(21.75/(100-21.75))/(9.88/(100-9.88))
#plot indirect
indirect_plot1 <- aggregate(response ~ condition*type_specific*val, indirect, mean)
indirect_plot1$se <- aggregate(response ~ condition*type_specific*val, indirect, se) [[4]]
barplot2 <- ggplot(indirect_plot1, aes (y = response, x = condition, fill = val)) +
facet_grid(. ~ type_specific) +
geom_col(position = position_dodge()) +
geom_errorbar(aes(ymin= response - se, ymax= response + se), width=.2,
position=position_dodge(.9)) +
geom_hline(yintercept = 0.5) +
ggtitle("AMP\n") +
scale_fill_brewer(palette = "Paired") +
scale_x_discrete(name = "\n Condition") +
scale_y_continuous (name = "AMP responses\n", limits = c(0,1)) +
theme_classic() +
labs(fill = "Valence") +
theme(plot.title = element_text (hjust = 0.5, face = "bold", size = 14),
text = element_text(size=14))
barplot2
barplot2
glmer2
exp(0.3)
exp(-0.05)
exp(0-258)
exp(-0.258)
aggregate(response ~ val*type_specific, glmer2_analysis, mean) #CS(27.7 + 37.46) - GS(15.76+19.93)
aggregate(response ~ val*type_specific, glmer2_analysis, mean)
14/20
exp(0.29)
9.88/19.53
19.53/9.88
9.88/19.53
18.33/21.72
18.33/21.72
aggregate(response ~ val*condition, glmer2_analysis, mean) #many(27.7 + 27.7) - one(15.08+29.67)
aggregate(response ~ val*condition, glmer2_analysis, mean) #many(27.7 + 27.7) - one(15.08+29.67)
14/20
64.29 - 42.67
64.85 - 51.15
21.62/13.7
13.7/21.62
1 - (13.7/21.62)
1 - 14/20
14/20
aggregate(response ~ type_specific*condition, glmer2_analysis, mean) #one(9.35 - 5.23) - many(1 + 1
aggregate(response ~ type_specific*condition, glmer2_analysis, mean) #one(9.35 - 5.23) - many(1 + 1
53.78 - 52.18
53.78 - 52.18
58.17 - 57.83
(21.62/(100-21.62))/(13.7/(100-13.7))
(13.7/(100-13.7))/(21.62/(100-21.62))
aggregate(response ~ type_specific*condition, glmer2_analysis, mean) #(53.78 - 52.18)
barplot2
lmer1_analysis #three-way interaction: (one: (23+41) - (7 + 17)) - (many: (31 + 33.12) - (24.46 + 22.31))
glmer2_analysis #three-way interaction: (one: (23+41) - (7 + 17)) - (many: (31 + 33.12) - (24.46 + 22.31))
(0.67-0.49) - (0.62-0.53)
glmer2_analysis
many: (0.65 - 0.43) - (0.62 - 0.42)
(0.65 - 0.43) - (0.62 - 0.42)
glmer2
exp(0.3)
#random intercept for participants
memory_glmer1 <- glmer(memoryResp ~ condition_effect * type_effect
+ (1|subject),
memory, binomial)
#random intercept and slope for stimuli for participants
memory_glmer2 <- glmer(memoryResp ~ condition_effect*type_effect
+ (type_effect|subject),
memory, binomial)
anova(memory_glmer1, memory_glmer2)
#model choice: glmer1
summary(glmer1, corr = FALSE)
#model choice: glmer1
summary(memory_glmer1, corr = FALSE)
memory_plot1
memory_plot2
memory_plot2$sd <- aggregate(memoryResp ~ condition + type, memory, sd)[[3]]
memory_plot2
memory_plot2$length <- aggregate(memoryResp ~ condition + type, memory, length)[[3]]
memory_plot2
memory_glmer1
summary(memory_glmer1)
#model choice: glmer1
summary(memory_glmer1, corr = FALSE, test = "LRT")
anova(memory_glmer1, memory_glmer2, , test = "LRT")
anova(memory_glmer1, memory_glmer2, test = "LRT")
memory_glmer1
summary(memory_glmer1)
exp (-2.64)
exp (2.64)
exp(-3.0)
exp(0.077)
exp(0.704)
#analyze simple slopes (even though three-way-interaction is not significant)
memory_glmer1 <- glmer(memoryResp ~ type_effect
+ condition_effect:type_specific
+ (1|subject),
memory, binomial)
str(memory)
memory_check <- aggregate(memoyResp ~ type*condition, memory, mean)
memory_check <- aggregate(memoryResp ~ type*condition, memory, mean)
memory_check
aggreagte(memoryResp ~ type, memory_check, mean)
aggregate(memoryResp ~ type, memory_check, mean)
aggregate(memoryResp ~ condition, memory_check, mean)
memory_glmer1
summary(memory_glmer1)
memory_check
(0.826-0.476)
0.942-0.186
#analyze simple slopes (even though three-way-interaction is not significant)
memory_glmer1 <- glmer(memoryResp ~ type_effect
+ condition_effect:type
+ (1|subject),
memory, binomial)
summary(memory_glmer1_1, corr = FALSE)
#analyze simple slopes (even though three-way-interaction is not significant)
memory_glmer1_1 <- glmer(memoryResp ~ type_effect
+ condition_effect:type
+ (1|subject),
memory, binomial)
summary(memory_glmer1_1, corr = FALSE)
exp(-1.24)
exp(1.40)
memory_check
