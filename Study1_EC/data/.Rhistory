samples_post_tim < samples_post_alex &
samples_post_alex < samples_post_felix &
samples_post_felix < samples_post_georg)/N
#H1/Hr
#store results
BFencomPrior[i] <- prior/posterior
}
#bridge sampling
for (i in 1:nrRepeat){
output <- binom_bf_informed(x1, n1, Hr1, a, b, niter = 2e3, factor_levels = factor_levels, bf_type = 'BFre')
BFbridgeSampl[i] <- summary(output)$bf
}
#compare:
mean(BFencomPrior)
mean(BFbridgeSampl)
range(BFencomPrior)
range(BFbridgeSampl)
## (e) compute Bayes factor for conditional encompassing approach
prior
a <- rep (1, 6)
b <- rep (1, 6)
#data
x1 <- c(3, 21, 5, 20, 26, 1)
n1 <- c(10, 50, 10, 29, 30, 5)
#hypothesis:
factor_levels <- c("vincent", "marteen", "tim", "alex", "felix", "georg")
Hr1 <- c("vincent < marteen < tim < alex < felix < georg")
#bridge sampling
output <- binom_bf_informed(x1, n1, Hr1, a, b, niter = 2e3, factor_levels = factor_levels, seed = 2020, bf_type = 'BFre')
#get Bayes Factor
summary(output)$bf
BFr1 <- summary(output)$bf
#in favor for alternative
1/BFr1
## (d) compute Bayes Factor 20 times; mean estimates & ranges
nrRepeat <- 20
BFencomPrior <- NULL
BFbridgeSampl <- NULL
#encompassing prior
for (i in 1:nrRepeat){
#data
#Vincent
samples_prior_vincent <- rbeta(N, a, b)
samples_post_vincent <- rbeta(N, a + 3, b + 7)
#Maarten
samples_prior_marteen <- rbeta(N, a, b)
samples_post_marteen <- rbeta(N, a + 21, b + 29)
#Tim
samples_prior_tim<- rbeta(N, a, b)
samples_post_tim <- rbeta(N, a + 5, b + 5)
#Alex
samples_prior_alex <- rbeta(N, a, b)
samples_post_alex <- rbeta(N, a + 20, b + 29)
#Felix
samples_prior_felix <- rbeta(N, a, b)
samples_post_felix <- rbeta(N, a + 26, b + 30)
#Georg
samples_prior_georg <- rbeta(N, a, b)
samples_post_georg <- rbeta(N, a + 1, b + 5)
#model
prior <- sum (samples_prior_vincent < samples_prior_marteen &
samples_prior_marteen < samples_prior_tim &
samples_prior_tim < samples_prior_alex &
samples_prior_alex < samples_prior_felix &
samples_prior_felix < samples_prior_georg)/N
#ordered: Hr
posterior <- sum (samples_post_vincent < samples_post_marteen &
samples_post_marteen < samples_post_tim &
samples_post_tim < samples_post_alex &
samples_post_alex < samples_post_felix &
samples_post_felix < samples_post_georg)/N
#H1/Hr
#store results
BFencomPrior[i] <- prior/posterior
}
#bridge sampling
for (i in 1:nrRepeat){
output <- binom_bf_informed(x1, n1, Hr1, a, b, niter = 2e3, factor_levels = factor_levels, bf_type = 'BFre')
BFbridgeSampl[i] <- summary(output)$bf
}
#compare:
mean(BFencomPrior)
mean(BFbridgeSampl)
range(BFencomPrior)
range(BFbridgeSampl)
## (e) compute Bayes factor for conditional encompassing approach
log(mean(BFencomPrior))
#plot
plot(bf_bridge)
p <- c(.135, .161, .128, .091, .058)
ci_hw <- c(.022, .01, .007, .01, .008)
se <- ci_hw/1.96
n <- round((p*(1-p))/(se)^2)
x <- round(n*p)
library(multibridge)
bf_bridge <- binom_bf_informed(x=x, n=n,
a=rep(1,5), b=rep(1,5),
factor_levels =paste("age",1:5),
Hr=c('age 1','<','age 2','<','age 3','<','age 4','<','age 5'),
bf_type = "BFer")
summary(bf_bridge)
#plot
plot(bf_bridge)
#plot
plot(summary(br_bridge))
#plot
plot(summary(bf_bridge))
6/94
7/93
6/100
7/100
6/100 + 7/100
100/6
6/100 / 7/100
6/7
7/6
0.07/0.06
(2/7000)/(1/7000)
(1/16)/(1/14)
(1/14)/(1/16)
(7/100)/(6/100)
(7/93)/(6/94)
(87/100)/(85/100)
(87/13)/(85/15)
2/100
9/94
6/94
(7/100)/(6/100)
6053/6967
5905/6967
100/87
87/100
100/6
100/7
100/15
87/3
87/13
85/15
(87/100)/(85/100)
(87/13)/(85/15)
6/94
7/93
0.06/0.07
0.07/0.06
0.08/0.06
6.7/5.7
3073/1667261
(3073/1667261)*100
26206/5775546
(26206/5775546)*100
0.45-9.18
0.45-0.18
(3073/1667261)*1000
(26206/5775546)*1000
85/15
(0.46/100)/(0.18/100)
(2/7000)/(1/7000)
(0.45/100)/(0.18/100)
100-0.18
0.18/99.82
0.45/99.55
(0.45/99.55)/(0.18/99.82)
108/1000
9/108
10/1000*9/10
990/1000*990/99
0.009+0.009
0.009+9.9
108/1000
0.01*0.9
0.009/0.9
0.009/0.01
9/1000 + 99/1000
9/1000
0.999*0.003
10/100000
0.01*0.9
9/1000
0.9*0.1
99/1000
0.09+0.009
0.009*0.01
(0.009*0.01)/0.11
1/11
(1/1000*1/1000)/(15/100000)
(1/10000*1/10000)/(15/100000)
((1/10000*1/10000)/(15/100000))*100
9/1000
0.01*0.9
0.009*1000
(9/1000)/(108/1000)
(9/1000)/(10/1000)
108/1000
(9/1000) / (108/1000)
19/1000 + 49/1000
19+49
19/68
19/20
1/50
53-9
9/53
44/1000 + 9/1000
44/53
44/50
70*0.03
70/0.03
2350*0.03
70*15
1800*0.03
54*70
54*15
1000*0.03
27000*0.03
22500*0.03
37500*0.03
3300*0.03
33000*0.03
### Rescola-Wagner model
## define function
update_RW <- function (value, alpha = .3, beta = .3, lambda=1){
#compute value of compound stimulus
value_compound <- sum(value)
#compute prediction error
prediction_error <- lambda - value_compound
#compute change in strength
value_change <- alpha*beta * prediction_error
#update the associative value
value <- value + value_change
#return the new value
return(value)
}
#### (1) simulate a conditioning experiment
n_trials <- 20
strength <- numeric(n_trials)
#to store the associative strength
for (trial in 2:n_trials){
strength[trial] <- update_RW(strength[trial-1])
#-1: for first trial, associative strength stays 0
}
#"present" CS-US pairings
#update associative strength at the end of each trial
print(strength)
plot(strength)
#### (2) simulate extinction
n_trials <- 50
strength <- numeric (n_trials)
lambda <- .3 #initial reward value
#trial 1-25: learning phase
#trial 26-50: extinction phase
for (trial in 2:n_trials){
#lambda = 0: CS presented without US
if (trial > 25){
lambda <- 0
}
#update associative strength with each trial
strength[trial] <- update_RW(
value = strength[trial - 1],
lambda = lambda
)
}
print(strength)
plot(strength)
#associative value is reverting to 0 when extinction phase starts:
#### (3) simulate blocking
n_trials <- 50
strength_A <- rep (0, n_trials)
strength_B <- rep (0, n_trials)
#trial 1-25: present A - US
#trial26-50: present AB - US
#alpha in learning phase, 0 because B is not presented
alpha <- c(.3, 0)
for (trial in 2:n_trials){
if (trial > 15){
alpha <- c(.3,.3) #blocking phase
}
#current associative strengths
v_old <- c(strength_A[trial-1], strength_B[trial-1])
#update associative strengths
v_new <- update_RW(
value = v_old,
alpha = alpha
)
#record new strengths
strength_A[trial] <- v_new[1]
strength_B[trial] <- v_new[2]
}
plot(strength_A, col= "red")
points(strength_B, col = "blue")
#### (4) simulate evaluative Conditioning
n_trials <- 20
lambda <- 1 # positive valence
#low variability: 2 cues
alpha <- c(.3, .3)
strengthLow <- matrix(0, n_trials, 2)
for (trial in 2:n_trials){
#current associative strength
v_old <- c(strengthLow[trial-1, 1], strengthLow[trial-1, 2])
print(v_old)
#update associative strengths
v_new <- update_RW(
value = v_old,
lambda = lambda,
alpha = alpha
)
print(v_new)
#encode new strengths
strengthLow[trial,] <- v_new
}
plot(strengthLow[,1], col = "lightblue")
points(strengthLow[,2], col = "blue")
#high variability: 6 cues
alpha <- c(.3, .3, 0, 0, 0, 0)
strength <- matrix(0, n_trials, 6)
for (trial in 2:n_trials){
#determine stimulus composition
if (trial > 4 && trial < 8){
alpha <- c (.3, 0, .3, 0, 0,0)
} else if (trial > 8 && trial < 12){
alpha <- c(.3, 0, 0, .3, 0, 0)
} else if (trial > 12 && trial < 16){
alpha <- c(.3, 0, 0, 0, .3, 0)
} else if (trial > 16 && trial < 20){
alpha <- c(.3, 0, 0, 0, 0, .3)
}
#current associative strength
v_old <- c(strength[trial-1, 1],
strength[trial-1, 2],
strength[trial-1, 3],
strength[trial-1, 4],
strength[trial-1, 5],
strength[trial-1, 6])
#update associative strengths
v_new <- update_RW(
value = v_old,
lambda = lambda,
alpha = alpha
)
#encode new strengths
strength[trial,] <- v_new
}
plot(strength[,1], col = "lightblue")
points(strength[,2], col = "blue")
points(strength[,3], col = "red")
points(strength[,4], col = "orange")
points(strength[,5], col = "green")
points(strength[,6], col = "grey")
#high variability: 6 cues, random dislay of stimuli (check for blocking)
alpha <- c(.3, .3, 0, 0, 0, 0)
strength <- matrix(0, n_trials, 6)
#randomize display order
display_order <- rep(sample(1:5, replace = FALSE, size = 5), 4)
for (trial in 2:n_trials){
#determine stimulus composition
if (display_order[trial] == 1){
alpha <- c(.3, .3, 0, 0, 0,0)
} else if (display_order[trial] == 2){
alpha <- c (.3, 0, .3, 0, 0,0)
} else if (display_order[trial] == 3){
alpha <- c(.3, 0, 0, .3, 0, 0)
} else if (display_order[trial] == 4){
alpha <- c(.3, 0, 0, 0, .3, 0)
} else {
alpha <- c(.3, 0, 0, 0, 0, .3)
}
#current associative strength
v_old <- c(strength[trial-1, 1],
strength[trial-1, 2],
strength[trial-1, 3],
strength[trial-1, 4],
strength[trial-1, 5],
strength[trial-1, 6])
#update associative strengths
v_new <- update_RW(
value = v_old,
lambda = lambda,
alpha = alpha
)
#encode new strengths
strength[trial,] <- v_new
}
plot(strength[,1], col = "lightblue")
points(strength[,2], col = "blue")
points(strength[,3], col = "red")
points(strength[,4], col = "orange")
points(strength[,5], col = "green")
points(strength[,6], col = "grey")
print(strength)
plot(strength)
plot(strengthLow[,1], col = "lightblue")
points(strengthLow[,2], col = "blue")
9/(9+99)
9/10
19/68
19/20
45/53
45/50
44/53
44/50
941/950
891/990
(0.08 * 0.11) / 0.1
108/1000
(0.9 * 0.11) / 0.1
(0.9 * 0.1) / 0.11
(0.9 * 0.01) / 0.11
(0.95 * 0.02) / 0.06
(0.95 * 0.02) / 0.068
53/1000
50/1000*44/1000
50/1000*44/50
44/1000
950/1000*9/950
53/1000
50/1000
(0.88*0.05) / 0.05
44/1000 + 9/1000
44/50
44/53
50/1000
44/50
53/1000
(0.88*0.05) / 0.053
strength[trial] <- update_RW(strength[trial -1])
update_RW <- function(value, alpha = .3, beta = .3, lambda = 1){
#value of compound stimulus: sum of individual strengths
value_compound <- sum(value)
#prediction errror: diff. between max. associative strength that the US supports & current associative strength for the compound
prediction_error <- lambda - value_compound
#compute change in strength
value_change <- alpha * beta * prediction_error
#update associative value
value <- value + value_change
#return new value
return (value)
}
### conditioning
n_trials <- 20
strength <- numeric(n_trials) #use to store associative strengths
for (trial in 2:n_trials){
strength[trial] <- update_RW(strength[trial -1])
}
plot(strength)
n_trials <- 50
strength <- numeric(n_trials)
lambda <- .3
for (trial in 2:n_trials){
#trial 1-25 extinction
if (trial > 25){
lambda <- 0
}
strength[trial] <- update_RW(
value = strength[trial -1],
lambda = lambda
)
}
plot(strength)
n_trials <- 50
#compound stimulus
strength_A <- rep(0, n_trials)
strength_B <- rep(0, n_trials)
#during first learning phase, B is not present (alpha = 0)
alpha <- c(0.3, 0)
for (trial in 2:n_trials){
#after trial 15, both components of the stimulus are present
if(trial > 15){
alpha <- c(.3, .3)
}
#current associative strengths
v_old <- c(strength_A[trial -1], strength_B[trial - 1])
#old associative strengths
v_new <- update_RW(
value = v_old,
alpha = alpha
)
#record the new strengths
strength_A[trial] <- v_new[1]
strength_B[trial] <- v_new[2]
}
plot(strength_A)
line(strength_B)
lines(strength_B)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/reich/Documents/GitHub/CSCond_analysis/Study1_EC/data")
#load packages
library(dplyr)
library(tidyverse)
library(ggplot2)
library(lme4)
#functions
CI <- function(x) qnorm(0.975)*sd(x)/sqrt(length(x))
se <- function(x) sd(x)/sqrt(length(x))
#read table
direct <- read.csv2('direct.csv', header = TRUE)
getwd()
setwd()
setwd("C:/Users/reich/Documents/GitHub/CSCond_analysis/Study1_EC/data")
read.csv2
#read table
direct <- read.csv2('direct.csv', header = TRUE)
getwd()
setwd("C:/Users/reich/Documents/GitHub/CSCond_analysis/Study1_EC/data")
#read table
direct <- read.csv2('direct.csv', header = TRUE)
getwd()
#read table
direct <- read.csv2('GitHub/CSCond_analysis/Study1_EC/data/direct.csv', header = TRUE)
#read table
direct <- read.csv2('/GitHub/CSCond_analysis/Study1_EC/data/direct.csv', header = TRUE)
setwd("C:/Users/reich/Documents/GitHub/CSCond_analysis/Study1_EC/data")
getwd()
#read table
direct <- read.csv2('direct.csv', header = TRUE)
