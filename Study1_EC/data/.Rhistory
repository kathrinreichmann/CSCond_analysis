0.01*0.9
0.009/0.9
0.009/0.01
9/1000 + 99/1000
9/1000
0.999*0.003
10/100000
0.01*0.9
9/1000
0.9*0.1
99/1000
0.09+0.009
0.009*0.01
(0.009*0.01)/0.11
1/11
(1/1000*1/1000)/(15/100000)
(1/10000*1/10000)/(15/100000)
((1/10000*1/10000)/(15/100000))*100
9/1000
0.01*0.9
0.009*1000
(9/1000)/(108/1000)
(9/1000)/(10/1000)
108/1000
(9/1000) / (108/1000)
19/1000 + 49/1000
19+49
19/68
19/20
1/50
53-9
9/53
44/1000 + 9/1000
44/53
44/50
70*0.03
70/0.03
2350*0.03
70*15
1800*0.03
54*70
54*15
1000*0.03
27000*0.03
22500*0.03
37500*0.03
3300*0.03
33000*0.03
### Rescola-Wagner model
## define function
update_RW <- function (value, alpha = .3, beta = .3, lambda=1){
#compute value of compound stimulus
value_compound <- sum(value)
#compute prediction error
prediction_error <- lambda - value_compound
#compute change in strength
value_change <- alpha*beta * prediction_error
#update the associative value
value <- value + value_change
#return the new value
return(value)
}
#### (1) simulate a conditioning experiment
n_trials <- 20
strength <- numeric(n_trials)
#to store the associative strength
for (trial in 2:n_trials){
strength[trial] <- update_RW(strength[trial-1])
#-1: for first trial, associative strength stays 0
}
#"present" CS-US pairings
#update associative strength at the end of each trial
print(strength)
plot(strength)
#### (2) simulate extinction
n_trials <- 50
strength <- numeric (n_trials)
lambda <- .3 #initial reward value
#trial 1-25: learning phase
#trial 26-50: extinction phase
for (trial in 2:n_trials){
#lambda = 0: CS presented without US
if (trial > 25){
lambda <- 0
}
#update associative strength with each trial
strength[trial] <- update_RW(
value = strength[trial - 1],
lambda = lambda
)
}
print(strength)
plot(strength)
#associative value is reverting to 0 when extinction phase starts:
#### (3) simulate blocking
n_trials <- 50
strength_A <- rep (0, n_trials)
strength_B <- rep (0, n_trials)
#trial 1-25: present A - US
#trial26-50: present AB - US
#alpha in learning phase, 0 because B is not presented
alpha <- c(.3, 0)
for (trial in 2:n_trials){
if (trial > 15){
alpha <- c(.3,.3) #blocking phase
}
#current associative strengths
v_old <- c(strength_A[trial-1], strength_B[trial-1])
#update associative strengths
v_new <- update_RW(
value = v_old,
alpha = alpha
)
#record new strengths
strength_A[trial] <- v_new[1]
strength_B[trial] <- v_new[2]
}
plot(strength_A, col= "red")
points(strength_B, col = "blue")
#### (4) simulate evaluative Conditioning
n_trials <- 20
lambda <- 1 # positive valence
#low variability: 2 cues
alpha <- c(.3, .3)
strengthLow <- matrix(0, n_trials, 2)
for (trial in 2:n_trials){
#current associative strength
v_old <- c(strengthLow[trial-1, 1], strengthLow[trial-1, 2])
print(v_old)
#update associative strengths
v_new <- update_RW(
value = v_old,
lambda = lambda,
alpha = alpha
)
print(v_new)
#encode new strengths
strengthLow[trial,] <- v_new
}
plot(strengthLow[,1], col = "lightblue")
points(strengthLow[,2], col = "blue")
#high variability: 6 cues
alpha <- c(.3, .3, 0, 0, 0, 0)
strength <- matrix(0, n_trials, 6)
for (trial in 2:n_trials){
#determine stimulus composition
if (trial > 4 && trial < 8){
alpha <- c (.3, 0, .3, 0, 0,0)
} else if (trial > 8 && trial < 12){
alpha <- c(.3, 0, 0, .3, 0, 0)
} else if (trial > 12 && trial < 16){
alpha <- c(.3, 0, 0, 0, .3, 0)
} else if (trial > 16 && trial < 20){
alpha <- c(.3, 0, 0, 0, 0, .3)
}
#current associative strength
v_old <- c(strength[trial-1, 1],
strength[trial-1, 2],
strength[trial-1, 3],
strength[trial-1, 4],
strength[trial-1, 5],
strength[trial-1, 6])
#update associative strengths
v_new <- update_RW(
value = v_old,
lambda = lambda,
alpha = alpha
)
#encode new strengths
strength[trial,] <- v_new
}
plot(strength[,1], col = "lightblue")
points(strength[,2], col = "blue")
points(strength[,3], col = "red")
points(strength[,4], col = "orange")
points(strength[,5], col = "green")
points(strength[,6], col = "grey")
#high variability: 6 cues, random dislay of stimuli (check for blocking)
alpha <- c(.3, .3, 0, 0, 0, 0)
strength <- matrix(0, n_trials, 6)
#randomize display order
display_order <- rep(sample(1:5, replace = FALSE, size = 5), 4)
for (trial in 2:n_trials){
#determine stimulus composition
if (display_order[trial] == 1){
alpha <- c(.3, .3, 0, 0, 0,0)
} else if (display_order[trial] == 2){
alpha <- c (.3, 0, .3, 0, 0,0)
} else if (display_order[trial] == 3){
alpha <- c(.3, 0, 0, .3, 0, 0)
} else if (display_order[trial] == 4){
alpha <- c(.3, 0, 0, 0, .3, 0)
} else {
alpha <- c(.3, 0, 0, 0, 0, .3)
}
#current associative strength
v_old <- c(strength[trial-1, 1],
strength[trial-1, 2],
strength[trial-1, 3],
strength[trial-1, 4],
strength[trial-1, 5],
strength[trial-1, 6])
#update associative strengths
v_new <- update_RW(
value = v_old,
lambda = lambda,
alpha = alpha
)
#encode new strengths
strength[trial,] <- v_new
}
plot(strength[,1], col = "lightblue")
points(strength[,2], col = "blue")
points(strength[,3], col = "red")
points(strength[,4], col = "orange")
points(strength[,5], col = "green")
points(strength[,6], col = "grey")
print(strength)
plot(strength)
plot(strengthLow[,1], col = "lightblue")
points(strengthLow[,2], col = "blue")
9/(9+99)
9/10
19/68
19/20
45/53
45/50
44/53
44/50
941/950
891/990
(0.08 * 0.11) / 0.1
108/1000
(0.9 * 0.11) / 0.1
(0.9 * 0.1) / 0.11
(0.9 * 0.01) / 0.11
(0.95 * 0.02) / 0.06
(0.95 * 0.02) / 0.068
53/1000
50/1000*44/1000
50/1000*44/50
44/1000
950/1000*9/950
53/1000
50/1000
(0.88*0.05) / 0.05
44/1000 + 9/1000
44/50
44/53
50/1000
44/50
53/1000
(0.88*0.05) / 0.053
strength[trial] <- update_RW(strength[trial -1])
update_RW <- function(value, alpha = .3, beta = .3, lambda = 1){
#value of compound stimulus: sum of individual strengths
value_compound <- sum(value)
#prediction errror: diff. between max. associative strength that the US supports & current associative strength for the compound
prediction_error <- lambda - value_compound
#compute change in strength
value_change <- alpha * beta * prediction_error
#update associative value
value <- value + value_change
#return new value
return (value)
}
### conditioning
n_trials <- 20
strength <- numeric(n_trials) #use to store associative strengths
for (trial in 2:n_trials){
strength[trial] <- update_RW(strength[trial -1])
}
plot(strength)
n_trials <- 50
strength <- numeric(n_trials)
lambda <- .3
for (trial in 2:n_trials){
#trial 1-25 extinction
if (trial > 25){
lambda <- 0
}
strength[trial] <- update_RW(
value = strength[trial -1],
lambda = lambda
)
}
plot(strength)
n_trials <- 50
#compound stimulus
strength_A <- rep(0, n_trials)
strength_B <- rep(0, n_trials)
#during first learning phase, B is not present (alpha = 0)
alpha <- c(0.3, 0)
for (trial in 2:n_trials){
#after trial 15, both components of the stimulus are present
if(trial > 15){
alpha <- c(.3, .3)
}
#current associative strengths
v_old <- c(strength_A[trial -1], strength_B[trial - 1])
#old associative strengths
v_new <- update_RW(
value = v_old,
alpha = alpha
)
#record the new strengths
strength_A[trial] <- v_new[1]
strength_B[trial] <- v_new[2]
}
plot(strength_A)
line(strength_B)
lines(strength_B)
---
title: 'Pre-Registration: Direct evalautive ratings'
author: "Kathrin Reichmann"
date: "26 5 2021"
input: "direct.csv"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Pre-Registration Experiment 1a - Category Size and Chinese Characters
The second task participants will do in the experiment is a direct evaluative rating task of CSs, GSs (stimuli from the same categories) and Distractors (unrelated stimuli) -> "type_specific" . CSs stem from one of four different categories. Categories were either paired with positive USs, or with negative USs.CSs consisted of chinese characters with two components: one component defined the category-membership (predictive component), the other varied between exemplars (non-predictive component).
Direct Evaluative Ratings are conducted on a -100 to 100 scale.
Category size of categories is varied between-subjects (one: one exemplar per category vs. many: five exemplars per category).
# Hypotheses:
(1) Generalization towards novel stimuli is more pronounced in the "many" condition than in the "one" condition.
(2) Evaluative ratings differ between predictive and non-predictive components for "many" condition. No difference between the components in the "one" condition.
```{r prep, echo = FALSE, include = FALSE}
#set directory
#setwd("\\\\sn00.zdv.uni-tuebingen.de/siskr01/Documents/Github/CSCond_analysis/CSCond_analysis/data")
setwd("C:/Users/reich/Documents/GitHub/CSCond_analysis/Study1_EC/data")
#load packages
library(dplyr)
library(tidyverse)
library(ggplot2)
library(lme4)
#functions
CI <- function(x) qnorm(0.975)*sd(x)/sqrt(length(x))
se <- function(x) sd(x)/sqrt(length(x))
```
```{r prepare data for generalization analysis, echo = FALSE, include = FALSE}
#read table
direct <- read.csv2('direct.csv', header = TRUE)
str(direct)
#convert to factor
as_factor <- c("subject", "val", "condition_code", "condition", "measure", "measure_code", "type", "type_specific", "category", "cs_selected")
for (factor in as_factor){
direct[, factor] <- as.factor(direct[,factor])
}
direct$type_specific <- factor(direct$type_specific, levels = c("CS", "GS same", "GS different", "Feature", "Group"))
#!! change in new study?
## randomly select 1 CSs for many_one:
new_one <- direct[direct$condition == "one_one",]
new_many <- direct[direct$condition == "many_one",]
new_many <- new_many[!new_many$type_specific == "CS",]
new_direct <- rbind(new_one, new_many)
for (subject in unique(direct$subject)){
if (direct$condition[direct$subject == subject] == "many_one"){
for (cat in 1:4){
temp <- direct[direct$subject == subject & direct$type_specific == "CS" & direct$category == cat,]
select <- temp[1,]
new_direct <- rbind(new_direct, select)
}
}
}
#!! Change in new study?
## exclude "Group" and "Feature" and "GSnew" for now.
new_direct$type <- NULL
new_direct <- new_direct[!new_direct$type_specific == "Group",]
new_direct <- new_direct[!new_direct$type_specific == "Feature",]
new_direct <- new_direct[!new_direct$type_specific == "GS different",]
## rename many_one to many and one_one to one
new_direct$condition <- factor(new_direct$condition, labels = c("many", "one"), levels = c("many_one", "one_one"))
#data frame taking each stimulus (cs_selected) into account
HLMprep <- aggregate(response ~ subject + condition + val + type_specific + category + cs_selected, new_direct, mean)
HLMprep$nr_obs <- aggregate(response ~ subject + condition + val + type_specific + category + cs_selected, new_direct, length)[[7]]
#!! check with Mandy
#calculate difference scores
HLMtarget <- HLMtarget[order(HLMtarget$subject, HLMtarget$val, HLMtarget$type_specific),]
HLMpos <- HLMprep[HLMprep$val == "pos",]
HLMpos$pos <- HLMpos$response
HLMpos$response <- NULL
head(HLMpos)
HLMneg <- HLMprep[HLMprep$val == "neg",]
HLMneg$neg <- HLMneg$response
HLM <- cbind(HLMpos, HLMneg$neg, HLMneg$category)
head(HLM)
HLM$val <- NULL
HLM$neg <- HLM$`HLMneg$neg`
HLM$`HLMneg$neg` <- NULL
dim(HLM)
HLM$diff <- HLM$pos - HLM$neg
# variable with type as a continuous predictor
HLM$type_continuous <- factor(HLM$type_specific, labels = c("0", "1"), levels = c("CS", "GS same"))
HLM$type_continuous <- as.numeric(HLM$type_continuous)
# variable with type as discrete predictor
HLM$type_discrete <- factor(HLM$type_specific, labels = c("CS", "GS"), levels = c("CS", "GS same"))
```
## (1) Testing H1: Multilevel Model with stimulus type (level 1) and condition (level 2) on difference scores (DV)
# Hypothesis (1): Significant cross-level interaction stimulus type x condition.
For each level of stimulus type:
(1a) no effect of condition on difference scores for **CSs**
(1b) effect of condition on difference scores for **GSs** : higher difference scores in the "many" condition than in the "one" condition
(1c) no effect of condition on difference scores for **distractors**
```{r }
```
```{r pressure, echo=FALSE}
plot(pressure)
```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
---
title: 'Pre-Registration: Direct evalautive ratings'
author: "Kathrin Reichmann"
date: "26 5 2021"
input: "direct.csv"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Pre-Registration Experiment 1a - Category Size and Chinese Characters
The second task participants will do in the experiment is a direct evaluative rating task of CSs, GSs (stimuli from the same categories) and Distractors (unrelated stimuli) -> "type_specific" . CSs stem from one of four different categories. Categories were either paired with positive USs, or with negative USs.CSs consisted of chinese characters with two components: one component defined the category-membership (predictive component), the other varied between exemplars (non-predictive component).
Direct Evaluative Ratings are conducted on a -100 to 100 scale.
Category size of categories is varied between-subjects (one: one exemplar per category vs. many: five exemplars per category).
# Hypotheses:
(1) Generalization towards novel stimuli is more pronounced in the "many" condition than in the "one" condition.
(2) Evaluative ratings differ between predictive and non-predictive components for "many" condition. No difference between the components in the "one" condition.
```{r prep, echo = FALSE, include = FALSE}
#set directory
#setwd("\\\\sn00.zdv.uni-tuebingen.de/siskr01/Documents/Github/CSCond_analysis/CSCond_analysis/data")
setwd("C:/Users/reich/Documents/GitHub/CSCond_analysis/Study1_EC/data")
#load packages
library(dplyr)
library(tidyverse)
library(ggplot2)
library(lme4)
#functions
CI <- function(x) qnorm(0.975)*sd(x)/sqrt(length(x))
se <- function(x) sd(x)/sqrt(length(x))
```
```{r prepare data for generalization analysis, echo = FALSE, include = FALSE}
#read table
direct <- read.csv2('direct.csv', header = TRUE)
str(direct)
#convert to factor
as_factor <- c("subject", "val", "condition_code", "condition", "measure", "measure_code", "type", "type_specific", "category", "cs_selected")
for (factor in as_factor){
direct[, factor] <- as.factor(direct[,factor])
}
direct$type_specific <- factor(direct$type_specific, levels = c("CS", "GS same", "GS different", "Feature", "Group"))
#!! change in new study?
## randomly select 1 CSs for many_one:
new_one <- direct[direct$condition == "one_one",]
new_many <- direct[direct$condition == "many_one",]
new_many <- new_many[!new_many$type_specific == "CS",]
new_direct <- rbind(new_one, new_many)
for (subject in unique(direct$subject)){
if (direct$condition[direct$subject == subject] == "many_one"){
for (cat in 1:4){
temp <- direct[direct$subject == subject & direct$type_specific == "CS" & direct$category == cat,]
select <- temp[1,]
new_direct <- rbind(new_direct, select)
}
}
}
#!! Change in new study?
## exclude "Group" and "Feature" and "GSnew" for now.
new_direct$type <- NULL
new_direct <- new_direct[!new_direct$type_specific == "Group",]
new_direct <- new_direct[!new_direct$type_specific == "Feature",]
new_direct <- new_direct[!new_direct$type_specific == "GS different",]
## rename many_one to many and one_one to one
new_direct$condition <- factor(new_direct$condition, labels = c("many", "one"), levels = c("many_one", "one_one"))
#data frame taking each stimulus (cs_selected) into account
HLMprep <- aggregate(response ~ subject + condition + val + type_specific + category + cs_selected, new_direct, mean)
HLMprep$nr_obs <- aggregate(response ~ subject + condition + val + type_specific + category + cs_selected, new_direct, length)[[7]]
#!! check with Mandy
#calculate difference scores
HLMprep <- HLMprep[order(HLMprep$subject, HLMprep$val, HLMprep$type_specific),]
HLMpos <- HLMprep[HLMprep$val == "pos",]
HLMpos$pos <- HLMpos$response
HLMpos$response <- NULL
head(HLMpos)
HLMneg <- HLMprep[HLMprep$val == "neg",]
HLMneg$neg <- HLMneg$response
HLM <- cbind(HLMpos, HLMneg$neg, HLMneg$category)
head(HLM)
HLM$val <- NULL
HLM$neg <- HLM$`HLMneg$neg`
HLM$`HLMneg$neg` <- NULL
dim(HLM)
HLM$diff <- HLM$pos - HLM$neg
# variable with type as a continuous predictor
HLM$type_continuous <- factor(HLM$type_specific, labels = c("0", "1"), levels = c("CS", "GS same"))
HLM$type_continuous <- as.numeric(HLM$type_continuous)
# variable with type as discrete predictor
HLM$type_discrete <- factor(HLM$type_specific, labels = c("CS", "GS"), levels = c("CS", "GS same"))
```
## (1) Testing H1: Multilevel Model with stimulus type (level 1) and condition (level 2) on difference scores (DV)
# Hypothesis (1): Significant cross-level interaction stimulus type x condition.
For each level of stimulus type:
(1a) no effect of condition on difference scores for **CSs**
(1b) effect of condition on difference scores for **GSs** : higher difference scores in the "many" condition than in the "one" condition
(1c) no effect of condition on difference scores for **distractors**
```{r }
```
```{r pressure, echo=FALSE}
plot(pressure)
```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
