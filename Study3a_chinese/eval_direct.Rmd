---
title: 'Pre-Registration Experiment 1a: Direct evalautive ratings'
author: "Kathrin Reichmann"
date: "26 5 2021"
input: "direct.csv"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## General Information

The second task participants will do in the experiment is a direct evaluative rating task of CSs, GSs (stimuli from the same categories) -> "type_specific" . CSs stem from one of four different categories. Categories were either paired with positive USs, or with negative USs. CSs consisted of chinese characters with two components: one component defined the category-membership (predictive component), the other varied between exemplars (non-predictive component).

Direct Evaluative Ratings are conducted on a -100 to 100 scale. Difference scores are calculated by subtracting e.g. category1 [US+] - category2 [US-] for every participant and measure.

Category size of categories ("condition") is varied between-subjects (one: one exemplar per category vs. many: five exemplars per category).

Stimulus type ("type_discrete") is a within-subjects variable (CS vs. GS. vs. distractor?) for generalization and (predictive vs. non-predictive) for components

Here: N = 200, nr. obs "CS" = 2, nr.obs."GS" = 6, nr. observations "predictive component" = 2

```{r prep, echo = FALSE, include = FALSE}
#set directory
knitr::opts_knit$set(root.dir = "C:/Users/reich/Documents/GitHub/CSCond_analysis/Study1_EC/data")

#load packages
library(dplyr)
library(tidyverse)
library(ggplot2)
library(lme4)
library(modelsummary)

#functions
CI <- function(x) qnorm(0.975)*sd(x)/sqrt(length(x))
se <- function(x) sd(x)/sqrt(length(x))

```

```{r prepare data for generalization analysis, echo = FALSE, include = FALSE}

#read table
direct <- read.csv2('direct.csv', header = TRUE)
str(direct)

#convert to factor
as_factor <- c("subject", "val", "condition_code", "condition", "measure", "measure_code", "type", "type_specific", "category", "cs_selected")

for (factor in as_factor){
  direct[, factor] <- as.factor(direct[,factor])
}

direct$type_specific <- factor(direct$type_specific, levels = c("CS", "GS same", "GS different", "Feature", "Group"))

#!! change in new study?
## randomly select 1 CSs for many_one:
new_one <- direct[direct$condition == "one_one",]
new_many <- direct[direct$condition == "many_one",]
new_many <- new_many[!new_many$type_specific == "CS",]
new_direct <- rbind(new_one, new_many)

for (subject in unique(direct$subject)){
  if (direct$condition[direct$subject == subject] == "many_one"){
    for (cat in 1:4){
      temp <- direct[direct$subject == subject & direct$type_specific == "CS" & direct$category == cat,]
      select <- temp[1,]
      new_direct <- rbind(new_direct, select)
    }
  }
}

new_direct$type <- NULL

## rename many_one to many and one_one to one
new_direct$condition <- factor(new_direct$condition, labels = c("many", "one"), levels = c("many_one", "one_one"))

```

## (1) Testing H1: Generalization

### Hypothesis 1: 
Generalization towards novel stimuli is wider in the "many" condition than in the "one" condition.

Dummy Coded: Stimulus Type (0 - CS, 1 - GS) and Condition (0 - One, 1 - Many)

(1a)
*non-significant fixed effect of condition*
-> no effect of condition on difference scores for **CSs**

(1b)
*Significant fixed effect for cross-level interaction stimulus type x condition.*
-> effect of condition on difference scores for **GSs** : higher difference scores in the "many" condition than in the "one" condition

### Plot raw data: 

```{r prep data for generalization analysis, include = FALSE, echo = FALSE}

#data frame taking each stimulus (cs_selected) into account
HLMprep <- aggregate(response ~ subject + condition + val + type_specific + category + cs_selected, new_direct, mean)
HLMprep$nr_obs <- aggregate(response ~ subject + condition + val + type_specific + category + cs_selected, new_direct, length)[[7]]

#!! check with Mandy
#calculate difference scores
HLMprep <- HLMprep[order(HLMprep$subject, HLMprep$val, HLMprep$type_specific),]

HLMpos <- HLMprep[HLMprep$val == "pos",]
HLMpos$pos <- HLMpos$response
HLMpos$response <- NULL
head(HLMpos)

HLMneg <- HLMprep[HLMprep$val == "neg",]
HLMneg$neg <- HLMneg$response
HLM <- cbind(HLMpos, HLMneg$neg, HLMneg$category)
head(HLM)

HLM$val <- NULL
HLM$neg <- HLM$`HLMneg$neg`
HLM$`HLMneg$neg` <- NULL
dim(HLM)

HLM$diff <- HLM$pos - HLM$neg

#exclude levels of "type_discrete" that are not needed
HLM <- HLM[!HLM$type_specific == "Group",]
HLM <- HLM[!HLM$type_specific == "Feature",]
HLM <- HLM[!HLM$type_specific == "GS different",]

# variable with type as a continuous predictor
HLM$type_continuous <- factor(HLM$type_specific, labels = c("0", "1"), levels = c("CS", "GS same"))
HLM$type_continuous <- as.numeric(HLM$type_continuous)

# variable with type as discrete predictor
HLM$type_discrete <- factor(HLM$type_specific, labels = c("CS", "GS"), levels = c("CS", "GS same"))

#reverse dummy coding for condiiton
HLM$condition <- factor(HLM$condition, labels = c("one", "many"), levels = c("one", "many"))

```

```{r plot raw data, include = TRUE, echo = FALSE}

#plot some individual slopes for condition "one"


indPlotData <- HLM[1:280,]
indPlotData <- indPlotData[order(indPlotData$subject),]

indPlot3 <- ggplot(indPlotData[!indPlotData$condition == "one",], aes(x = type_discrete, y = diff, group = subject, color = condition, shape = condition)) +
  facet_wrap(.~ subject, nrow = 5) +
  geom_point(show.legend = TRUE, alpha = .6) +
  geom_smooth(method = "lm", alpha = .6, se = FALSE) +  
  scale_color_brewer(palette = "Paired") 
indPlot3

#plot some individual slopes for condition "many"
indPlotData <- HLM[1:280,]
indPlotData <- indPlotData[order(indPlotData$subject),]
indPlot3 <- ggplot(indPlotData[!indPlotData$condition == "many",], aes(x = type_discrete, y = diff, group = subject, color = condition, shape = condition)) +
  facet_wrap(.~ subject, nrow = 5) +
  geom_point(show.legend = TRUE, alpha = .6) +
  geom_smooth(method = "lm", alpha = .6, se = FALSE) +  
  scale_color_brewer(palette = "Paired") 
indPlot3


#aggregate data
HLMdotplot <- aggregate(diff ~ subject + type_discrete + condition, HLM, mean)
means <- aggregate(diff ~ condition + type_discrete, HLM, mean)
means$se <- aggregate(diff ~ condition + type_discrete, HLM, se)[[3]]
means

#plot every single participant
dotplot1 <- ggplot(HLMdotplot, aes (x = type_discrete, y = diff, group = subject, color = condition, shape = condition)) +
  geom_line() +
  geom_point(show.legend = TRUE, alpha = .4) +
  geom_point(data = means, size = 4, alpha = .9) +
  geom_line(data = means, mapping = aes(group = condition), color = "red", size = 1) +
  scale_color_brewer(palette = "Paired") +
  scale_x_discrete(name = "\nStimulus Type") +
  scale_y_continuous (name = "Difference Scores for subjects i and stimulus j\n", breaks = seq(-100, 200, 50), limits = c(-100, 200)) + 
  theme_classic() +
  ggtitle("Raw Data") +
  labs(fill = "Condition") +
  theme(plot.title = element_text (hjust = 0.5, face = "bold", size = 12))
dotplot1

#barplot with standard errors
barplotDiff <- ggplot(means, aes (x = type_discrete, y = diff, fill = condition)) +
  geom_bar(stat = 'identity', position = position_dodge(), show.legend = TRUE) +
  geom_errorbar(aes(ymin= diff - se, ymax= diff + se), width=.2,
                position=position_dodge(.9)) +
  ggtitle("Mean Differences (with Standard Errors)") + 
  scale_fill_brewer(palette = "Paired") +
  scale_x_discrete(name = "\nType") +
  scale_y_continuous (name = "Mean Difference Scores\n", breaks = seq(0, 100, 10), limits = c(0, 100)) + 
  theme_classic() +
  labs(fill = "Condition") +
  theme(plot.title = element_text (hjust = 0.5, face = "bold", size = 12))
barplotDiff


```

### Model 1: random intercept, fixed effect of stimulus type

```{r model 1, echo = TRUE, include = FALSE}
##### random intercept model with fixed effect of stimulus type
model1 <- lmer(diff ~ type_discrete + (1|subject), data = HLM, REML = FALSE)
summary(model1)

```
```{r plot model1, echo = FALSE, include = TRUE}

#create data frame for plotting random effects
random1CS <- data.frame(diff = coef(model1)$subject[,1], type_discrete = "CS", subject = rownames(coef(model1)$subject))
random1GS <- data.frame(diff = coef(model1)$subject[,1] + coef(model1)$subject[,2], type_discrete = "GS", subject = rownames(coef(model1)$subject))
random1 <- rbind(random1CS, random1GS)

#fixed effect
fix1CS <- data.frame(diff = summary(model1)$coef[1, "Estimate"], type_discrete = "CS")
fix1GS <- data.frame(diff = summary(model1)$coef[1, "Estimate"] + summary(model1)$coef[2, "Estimate"], type_discrete = "GS")
fix1 <- rbind(fix1CS, fix1GS)
fix1

plotModel1 <- ggplot(random1, aes (x = as.factor(type_discrete), y = diff, group = as.factor(subject))) +
  geom_line(color = "grey") +
  geom_point(color = "grey") +
  geom_line(data = fix1, mapping = aes(y = diff, x = type_discrete, group = 1), color = "red", size = 1) +
  geom_point(data = fix1, mapping = aes(y = diff, x = type_discrete, group = 1), color = "red", size = 1.5) +
  scale_color_brewer(palette = "Paired") +
  scale_x_discrete (name = "\nStimulus Type", limits=c("CS","GS")) +
  scale_y_continuous (name = "Difference Scores for subjects i and stimulus j\n", breaks = seq(-100, 200, 50), limits = c(-100, 200)) + 
  theme_classic() +
  ggtitle("Data fitted under Model 1") +
  labs(fill = "condition\n subject i") +
  theme(plot.title = element_text (hjust = 0.5, face = "bold", size = 12))
plotModel1  


```

### Model 2: + random slope

```{r model 2m echo = TRUE, include = FALSE}
##### + random slope
model2 <- lmer(diff ~ type_discrete + (type_discrete|subject), data = HLM, REML = FALSE)
summary(model2)

```

```{r plot model 2, include = TRUE, echo = FALSE}

#create data frame for plotting random effects
random2CS <- data.frame(diff = coef(model2)$subject[,1], type_discrete = "CS", subject = rownames(coef(model2)$subject))
random2GS <- data.frame(diff = coef(model2)$subject[,1] + coef(model2)$subject[,2], type_discrete = "GS", subject = rownames(coef(model2)$subject))
random2 <- rbind(random2CS, random2GS)

#fixed effect
fix2CS <- data.frame(diff = summary(model2)$coef[1, "Estimate"], type_discrete = "CS")
fix2GS <- data.frame(diff = summary(model2)$coef[1, "Estimate"] + summary(model2)$coef[2, "Estimate"], type_discrete = "GS")
fix2 <- rbind(fix2CS, fix2GS)
fix2

plotModel2 <- ggplot(random2, aes (x = as.factor(type_discrete), y = diff, group = as.factor(subject))) +
  geom_line(color = "grey") +
  geom_point(color = "grey") +
  geom_line(data = fix2, mapping = aes(y = diff, x = type_discrete, group = 1), color = "red", size = 1) +
  geom_point(data = fix2, mapping = aes(y = diff, x = type_discrete, group = 1), color = "red", size = 1.5) +
  scale_color_brewer(palette = "Paired") +
  scale_x_discrete (name = "\nStimulus Type", limits=c("CS","GS")) +
  scale_y_continuous (name = "Difference Scores for subjects i and stimulus j\n", breaks = seq(-100, 200, 50), limits = c(-100, 200)) + 
  theme_classic() +
  ggtitle("Data fitted under Model 2") +
  labs(fill = "condition\n subject i") +
  theme(plot.title = element_text (hjust = 0.5, face = "bold", size = 12))
plotModel2 

```

### + condition (between-subjects variable)

```{r, include = TRUE, echo = TRUE}

# + between-subjects factor condition
model3 <- lmer(diff ~ type_discrete*condition + (type_discrete|subject), data = HLM, REML = FALSE)

```


### Model comparisons: 

```{r echo = TRUE, include = TRUE}
#model comparison
anova(model1, model2, model3)

```

Interpretation: 

+ The difference in deviance between Model 1 and Model 2 is not significant X²(2, 1594) = 2.48, p = .288. This indicates that including a random slope effect does not contribute to a better fitting model than a mere random intercept effect.

+ The difference in deviance between Model 2 and Model 3 is significant X²(2, 1592) = 20.97, p < .001. The inclusion of „condition“ as a cross-level interaction with stimulus type significantly contributes to the fit of the model, meaning that „condition“ explains variability in the intercept and slope. *(nimmt jedoch von model 2 auf model 3 zu) *

+ *For final model, omit random slope effect?*


### Results of Model 3:

```{r echo = FALSE, include = TRUE}
summary(model3)
```

Dummy Coded: Stimulus Type (0 - CS, 1 - GS) and Condition (0 - One, 1 - Many)


Interpretation: 

+ **intercept estimate:** mean difference score for „CS“ is 64.91 in the „one“ condition.

+ **ConditionMany [Gruppeneffekt]:**  On average, the difference score is reduced by -0.75 points for CSs in the „many“ condition in comparison to CSs in the „one“ condition. **H1a: non-significant**

+ **Type_discreteGS [Generalisierung]:** In the „one“ condition, the mean difference score is reduced by -40.30 points for GSs, in comparison to CSs. -> not interesting

+ **Type_discreteGS:conditionMany:** In "many" condition, the average difference score for GSs is 22.91 higher than the average difference scores for GSs in the "one" condition -> higher diff scores mean wider generalization **H2b: significant -> use for power analysis?**

+ **Random intercept [45.72]:** variation of intercept across subjects: variation goes beyond the fixed effect of stimulus type [-17.39]

+ **Random slopes [8.22]:** variation of slopes across subjects: individual differences in the degree of generalization -> individuals differ beyond the individual differences explained by the „condition“ variable


```{r plot model 3, include = TRUE, echo = FALSE}
#create data frame for plotting random effects
subjcond <- HLM[!duplicated(HLM$subject),c("subject", "condition")] ##add condition

random3CS <- data.frame(diff = coef(model3)$subject[,1], type_discrete = "CS", subject = rownames(coef(model3)$subject))
random3CS <- merge(random3CS, subjcond, by.y = "subject")

random3GS <- data.frame(diff = coef(model3)$subject[,1] + coef(model3)$subject[,2], type_discrete = "GS", subject = rownames(coef(model3)$subject))
random3GS <- merge(random3GS, subjcond, by.y = "subject")

random3 <- rbind(random3CS, random3GS)

#fixed effect
fix3CSMany <- data.frame(diff = summary(model3)$coef[1, "Estimate"], type_discrete = "CS")
fix3GSMany <- data.frame(diff = summary(model3)$coef[1, "Estimate"] + summary(model3)$coef[2, "Estimate"], type_discrete = "GS")
fix3Many <- rbind(fix3CSMany, fix3GSMany)
fix3Many

fix3CSOne <- data.frame(diff = summary(model3)$coef[1, "Estimate"] + summary(model3)$coef[3, "Estimate"], type_discrete = "CS")
fix3GSOne <- data.frame(diff = (summary(model3)$coef[1, "Estimate"] + summary(model3)$coef[3, "Estimate"]) + (summary(model3)$coef[2, "Estimate"] + summary(model3)$coef[4, "Estimate"]), type_discrete = "GS")
fix3One <- rbind(fix3CSOne, fix3GSOne)
fix3One


plotModel3 <- ggplot(random3, aes (x = as.factor(type_discrete), y = diff, group = as.factor(subject), color = condition)) +
  geom_line(alpha = .6) +
  geom_point(alpha = .4) +
  geom_line(data = fix3Many, mapping = aes(y = diff, x = type_discrete, group = 1), color = "red", size = 1) +
  geom_point(data = fix3Many, mapping = aes(y = diff, x = type_discrete, group = 1), color = "red", size = 1.5) +
  geom_text(data = fix3Many, mapping = aes(y = diff, x = type_discrete, group = 1), label = "many", color = "red", vjust = -1) +
  geom_line(data = fix3One, mapping = aes(y = diff, x = type_discrete, group = 1), color = "darkred", size = 1) +
  geom_point(data = fix3One, mapping = aes(y = diff, x = type_discrete, group = 1), color = "darkred", size = 1.5) +
  geom_text(data = fix3One, mapping = aes(y = diff, x = type_discrete, group = 1), label = "one", color = "darkred", vjust = 1) +
  scale_color_brewer(palette = "Paired") +
  scale_x_discrete (name = "\nStimulus Type", limits=c("CS","GS")) +
  scale_y_continuous (name = "Difference Scores for subjects i and stimulus j\n", breaks = seq(-100, 200, 50), limits = c(-100, 200)) + 
  theme_classic() +
  ggtitle("Data fitted under Model 3") +
  theme(plot.title = element_text (hjust = 0.5, face = "bold", size = 12))
plotModel3 
```

```{r simple slopes to investigate hypotheses directly, include = TRUE, echo = TRUE}

#simple slopes
CSs <- lm (diff ~ condition, HLM[HLM$type_discrete == "CS",])
summary(CSs) #400 observations

GSs <- lm (diff ~ condition, HLM[HLM$type_discrete == "GS", ])
summary(GSs) #1200 observations -> ? higher power in this condition

```

Interpretation:

**H1a:** (CSs not significant) In line with the prediction that condition does not impact evaluations of CSs

**H2a:** (GSs significant) In line with the prediction that condition impacts evaluations of GSs, the positive value indicates that  difference scores are higher in the "many" condition than in the "one" condition for GSs

-> calculation of simple slopes does not bring additional information in this case

```{r use model 3 to plot individual slopes, echo = FALSE, include = FALSE}



```


## (2) Testing H2: CS Components

### Hypothesis 2: 
Evaluative ratings differ between predictive and non-predictive components for "many" condition. No difference between the components in the "one" condition.

Explanation: In the „many“ condition, the EC effect gets attached to the category-defining feature, while in the „one“ condition, the EC effect gets attached to the whole stimulus


Dummy Coded: Stimulus Component (0 - Non-Predictive , 1 - Predictive) and Condition (0 - One, 1 - Many)

(2a)
* non-significant fixed effect for stimulus component, when ref. category is "one"*
  + no difference between components in **"one" condition**
  
(2b)
* significant fixed effect for the cross-level interaction stimulus component x condition, when ref. category is "one".*
  + difference between components in **many condition** goes beyond difference in components in "one" condition
  -> simple slope:
  + significant difference between components in the **many condition** : significant decrease in difference scores for the "predictive" component than the "non-predictive" component


### Plot raw data [predtivie, non-predictive is hypothetical]: 

```{r prep data for component analysis, echo = FALSE, include = FALSE}

#right now: do not take different targets into account (participants are nested within targets)
temp <- aggregate(response ~ subject + condition + val + type_specific + category, new_direct, mean)
temp$nr_obs <- aggregate(response ~ subject + condition + val + type_specific + category, new_direct, length)[[6]]
temp$nr_obs

## order data
temp <- temp[order(temp$subject, temp$val, temp$type_specific),]

## cbind positive and negative scores
HLMpos <- temp[temp$val == "pos",]
HLMpos$pos <- HLMpos$response
HLMpos$response <- NULL

HLMneg <- temp[temp$val == "neg",]
HLMneg$neg <- HLMneg$response
HLM <- cbind(HLMpos, HLMneg$neg, HLMneg$category)

HLM$val <- NULL
HLM$neg <- HLM$`HLMneg$neg`
HLM$`HLMneg$neg` <- NULL

## calculate difference scores
HLM$diff <- HLM$pos - HLM$neg

#reverse dummy coding for condiiton
HLM$condition <- factor(HLM$condition, labels = c("one", "many"), levels = c("one", "many"))

## discard levels of type we don't need
HLM <- HLM[!HLM$type_specific == "Group",]
HLM <- HLM[!HLM$type_specific == "GS different",]
HLM <- HLM[!HLM$type_specific == "GS same",]
HLM <- HLM[!HLM$type_specific == "CS",]


##categorical variable: generalization as discrete
HLM$type_discrete <- factor(HLM$type_specific, labels = c("predictive"), levels = c("Feature"))


```

```{r plot data with hypothetical results, include = TRUE, echo = FALSE}

means <- aggregate(diff ~ type_discrete + condition, HLM, mean)
means$se <- aggregate(diff ~ type_discrete + condition, HLM, se)[[3]]
means

##add hypothetical data
means$type_discrete <- as.character(means$type_discrete)
hypoMany <- c("non-predictive", "many", 18, 0)
hypoOne <- c("non-predictive", "one", 22, 0)
means <- rbind(means, hypoMany, hypoOne)
means$type_discrete <- as.factor(means$type_discrete)
means$diff <- as.numeric(means$diff)
means$se <- as.numeric(means$se)
means

#barplot with standard errors
barplotDiff <- ggplot(means, aes (x = condition, y = diff, fill = type_discrete)) +
  geom_bar(stat = 'identity', position = position_dodge(), show.legend = TRUE) +
  geom_errorbar(aes(ymin= diff - se, ymax= diff + se), width=.2,
                position=position_dodge(.9)) +
  ggtitle("Evaluative Ratings for Components (non-predictive is hypothetical)") + 
  scale_fill_brewer(palette = "Set3") +
  scale_x_discrete(name = "\nCondition") +
  scale_y_continuous (name = "Mean Difference Scores\n", breaks = seq(0, 100, 10), limits = c(0, 100)) + 
  theme_classic() +
  labs(fill = "Component") +
  theme(plot.title = element_text (hjust = 0.5, face = "bold", size = 12))
barplotDiff

```

### model for data analysis:

```{r multilevel model, echo = TRUE, include = FALSE}

#hypothetical second level of factor type_discrete
HLM2 <- HLM
HLM2$type_discrete <- factor(HLM$type_specific, labels = c("non-predictive"), levels = c("Feature"))
HLM <- rbind(HLM2, HLM)

#reverse dummy coding for condition
HLM$condition <- factor(HLM$condition, labels = c("one", "many"), levels = c("one", "many"))


##### random intercept model with fixed effect of stimulus type
model1 <- lmer(diff ~ type_discrete + (1|subject), data = HLM, REML = FALSE)
summary(model1)

##### + random slope
model2 <- lmer(diff ~ type_discrete + (type_discrete|subject), data = HLM, REML = FALSE)
summary(model2)

##### + between-subjects factor condition
model3 <- lmer(diff ~ type_discrete*condition + (type_discrete|subject), data = HLM, REML = FALSE)
summary(model3)

sjPlot::tab_model(model1, model2, model3, dv.labels = c("Model 1", "Model 2", "Model 3"))

```

Dummy Coded: Stimulus Component (0 - Non-Predictive , 1 - Predictive) and *Condition (0 - One, 1 - Many) - reversed for H2*

Interpretation: (what we would predict)

+ **intercept estimate:** mean difference score for „non-predictive“ is XX in the „one“ condition.

+ **ConditionMany [Gruppeneffekt]:**  On average, the difference score is reduced by XX points for non-predictive in the „many“ condition in comparison to non-predictive in the „one“ condition. -> **hypothesis 2b: significant**

+ **Type_discretePredictive [Component]:** In the „one“ condition, the mean difference score increases by XX points for predictive components, in comparison to non-predictive components -> **hypothesis 2a: not significant**

+ **Type_discretePredictive:conditionMany:** In the "many" condition, the average difference score for "predictive" components is XX higher than the average difference score for "predictive" Components in the "one" condition -> **hypothesis 2b: significant**

+ **Random intercept [XX]:** variation of intercept across subjects: variation goes beyond the fixed effect of stimulus type [XX]

+ **Random slopes [XX]:** variation of slopes across subjects: individual differences in the evaluations of the components -> individuals differ beyond the individual differences explained by the „condition“ variable

```{r observe H1a and H2b directly, include = TRUE, echo = FALSE}

one <- lm (diff ~ type_discrete, data = HLM[HLM$condition == "one", ])
summary(one)

many <- lm (diff ~ type_discrete, data = HLM[HLM$condition == "many", ])
summary(many)

```

Interpretation: (what we would predict)

**H2a**: ("one" is non-significant) in line with the prediction that components are evaluated equally in the "one" condition

**H2b**: ("many" is significant, positive parameter) in line with the prediction that predictive components have higher difference scores than non-predictive components 

## (3) Alternative way of approaching H1 (use "CS ratings" as a predictor, control for categories)

### Hypothesis 1: 
Generalization towards novel stimuli is wider in the "many" condition than in the "one" condition.

CS ratings as the continuous predictor. GS as the outcome variable. Both z-standardized.
Condition as the between-subjects variable.

(1)
*significant interaction CS and condition*
-> predictive value of CS to predict GS ratings depends on the different conditions
-> slope is steeper for "one" than for "many"

### plot prediction of "GS" with "CS", controlling for categories

```{r plot new model, include = TRUE, echo = FALSE}


#(1) mean scores for every category and participant
centerDirect <- aggregate(response ~ subject + condition + category + type_specific + val, new_direct, mean)
#condition_code: 0 =  many
centerDirect[centerDirect$subject == "02a80kdxm7",] #check


#(2) use CS as predictor for GS same
multiLevel <- centerDirect[centerDirect$type_specific == "CS",]
respGS <- centerDirect[centerDirect$type_specific == "GS same",]
multiLevel$GS <- respGS$response
multiLevel$CS <- multiLevel$response
multiLevel$response <- NULL
multiLevel$type_specific <- NULL

#z-standardize GS and CS
multiLevel$GS <- scale (multiLevel$GS, center = TRUE, scale = TRUE)
multiLevel$CS <- scale (multiLevel$CS, center = TRUE, scale = TRUE)

#(3) plot the two different levels involved in the analysis

dotplot <- ggplot(multiLevel, aes (x = CS, y = GS, color = category)) +
  facet_grid(. ~ condition) +
  geom_point(show.legend = TRUE) +
  geom_smooth(method = 'lm') +
  scale_color_brewer(palette = "Paired") +
  scale_x_continuous(name = "\nCS Ratings") +
  scale_y_continuous (name = "GS (new) Ratings\n") + 
  theme_classic() +
  labs(fill = "Categories") +
  theme(plot.title = element_text (hjust = 0.5, face = "bold", size = 12))
dotplot

```

```{r models, include = TRUE, echo = TRUE}


#(4) build up the models

#add random intercept for category
lmer1 <- lmer(GS ~ 1 + (1| subject), data = multiLevel, REML = FALSE)

#add CSs as predictor
lmer2 <- lmer(GS ~ CS + (1 | subject), data = multiLevel, REML = FALSE)

#add random slopes
lmer3 <- lmer(GS ~ CS + (CS | subject), data = multiLevel, REML = FALSE )

#add interaction with condition
lmer4 <- lmer(GS ~ CS*condition + (CS | subject), data = multiLevel, REML = FALSE )

#(5) pick best model
anova(lmer1, lmer2, lmer3, lmer4)

#(6) results
sjPlot::tab_model(lmer1, lmer2, lmer3, lmer4, dv.labels = c("Null Model", "Model 1"))

```

